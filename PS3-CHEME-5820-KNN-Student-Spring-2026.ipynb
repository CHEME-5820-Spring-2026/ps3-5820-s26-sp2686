{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ebe7831",
   "metadata": {},
   "source": [
    "# PS3: Let's Classify RNA data using K-Nearest Neighbors (KNN)\n",
    "In this problem set, we will implement the K-Nearest Neighbors (KNN) algorithm to classify RNA data.\n",
    "\n",
    "Complete the TODO code cells in order, then answer the discussion questions and run the tests.\n",
    "\n",
    "> __Learning Objectives:__\n",
    ">\n",
    "> By the end of this problem set, you should be able to:\n",
    "> * __Prepare RNA data for distance-based classification:__ Parse the LIBSVM training and test files and package each example as a feature-label pair. Apply z-score scaling to each feature so no single feature range dominates distance calculations.\n",
    "> * __Build and run a kernelized KNN model:__ Define an RBF kernel and verify the sampled kernel matrix is positive semidefinite. Construct a weighted KNN classifier from reference samples and predict labels on a configurable test subset.\n",
    "> * __Evaluate model behavior with task-relevant metrics:__ Compute confusion-matrix counts together with accuracy, precision, recall, balanced accuracy, and F1 for RNA label predictions. Interpret a sweep over `K` and `gamma` to understand tradeoffs between overall correctness and positive-class recovery.\n",
    "\n",
    "Let's get started!\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cabe961",
   "metadata": {},
   "source": [
    "## Setup, Data, and Prerequisites\n",
    "First, we set up the computational environment by including the `Include.jl` file and loading any needed resources.\n",
    "\n",
    "> __Environment Setup with Include.jl__\n",
    ">\n",
    "> The [`include(...)` command](https://docs.julialang.org/en/v1/base/base/#include) evaluates the contents of the input source file, `Include.jl`, in the notebook's global scope. The `Include.jl` file sets paths, loads required external packages, etc. For additional information on functions and types used in this material, see the [Julia programming language documentation](https://docs.julialang.org/en/v1/).\n",
    "\n",
    "Let's set up our code environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9ee499",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m git-repo `https://github.com/varnerlab/VLDataScienceMachineLearningPackage.jl.git`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m Graphs ───────────── v1.14.0\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m PtrArrays ────────── v1.4.0\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m Preferences ──────── v1.5.2\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m LinearOperators ──── v2.13.0\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m StaticArrays ─────── v1.9.17\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m SolverCore ───────── v0.3.10\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m NLPModels ────────── v0.21.11\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m IJulia ───────────── v1.34.4\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m MbedTLS ──────────── v1.1.10\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m StringManipulation ─ v0.4.4\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m MultivariateStats ── v0.10.4\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m KernelFunctions ──── v0.10.67\n",
      "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m `~/Downloads/CHEME-5820-Lectures-Spring-2026/ps3-5820-s26-sp2686/Project.toml`\n",
      "  \u001b[90m[5ae59095] \u001b[39m\u001b[92m+ Colors v0.13.1\u001b[39m\n",
      "  \u001b[90m[a93c6f00] \u001b[39m\u001b[92m+ DataFrames v1.8.1\u001b[39m\n",
      "  \u001b[90m[b4f34e82] \u001b[39m\u001b[92m+ Distances v0.10.12\u001b[39m\n",
      "  \u001b[90m[7073ff75] \u001b[39m\u001b[92m+ IJulia v1.34.4\u001b[39m\n",
      "  \u001b[90m[ec8451be] \u001b[39m\u001b[92m+ KernelFunctions v0.10.67\u001b[39m\n",
      "  \u001b[90m[91a5bcdd] \u001b[39m\u001b[92m+ Plots v1.41.6\u001b[39m\n",
      "  \u001b[90m[08abe8d2] \u001b[39m\u001b[92m+ PrettyTables v3.2.3\u001b[39m\n",
      "  \u001b[90m[10745b16] \u001b[39m\u001b[92m+ Statistics v1.11.1\u001b[39m\n",
      "  \u001b[90m[f3b207a7] \u001b[39m\u001b[92m+ StatsPlots v0.15.8\u001b[39m\n",
      "  \u001b[90m[24b76065] \u001b[39m\u001b[92m+ VLDataScienceMachineLearningPackage v0.1.0 `https://github.com/varnerlab/VLDataScienceMachineLearningPackage.jl.git#main`\u001b[39m\n",
      "  \u001b[90m[37e2e46d] \u001b[39m\u001b[93m~ LinearAlgebra ⇒ v1.12.0\u001b[39m\n",
      "  \u001b[90m[9a3f8284] \u001b[39m\u001b[93m~ Random ⇒ v1.11.0\u001b[39m\n",
      "  \u001b[90m[8dfed614] \u001b[39m\u001b[93m~ Test ⇒ v1.11.0\u001b[39m\n",
      "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m `~/Downloads/CHEME-5820-Lectures-Spring-2026/ps3-5820-s26-sp2686/Manifest.toml`\n",
      "  \u001b[90m[14f7f29c] \u001b[39m\u001b[92m+ AMD v0.5.3\u001b[39m\n",
      "  \u001b[90m[621f4979] \u001b[39m\u001b[92m+ AbstractFFTs v1.5.0\u001b[39m\n",
      "  \u001b[90m[1520ce14] \u001b[39m\u001b[92m+ AbstractTrees v0.4.5\u001b[39m\n",
      "  \u001b[90m[79e6a3ab] \u001b[39m\u001b[92m+ Adapt v4.4.0\u001b[39m\n",
      "  \u001b[90m[66dad0bd] \u001b[39m\u001b[92m+ AliasTables v1.1.3\u001b[39m\n",
      "  \u001b[90m[ec485272] \u001b[39m\u001b[92m+ ArnoldiMethod v0.4.0\u001b[39m\n",
      "  \u001b[90m[7d9fca2a] \u001b[39m\u001b[92m+ Arpack v0.5.4\u001b[39m\n",
      "  \u001b[90m[4fba245c] \u001b[39m\u001b[92m+ ArrayInterface v7.22.0\u001b[39m\n",
      "  \u001b[90m[a9b6321e] \u001b[39m\u001b[92m+ Atomix v1.1.2\u001b[39m\n",
      "  \u001b[90m[13072b0f] \u001b[39m\u001b[92m+ AxisAlgorithms v1.1.0\u001b[39m\n",
      "  \u001b[90m[39de3d68] \u001b[39m\u001b[92m+ AxisArrays v0.4.8\u001b[39m\n",
      "  \u001b[90m[6e4b80f9] \u001b[39m\u001b[92m+ BenchmarkTools v1.6.3\u001b[39m\n",
      "  \u001b[90m[d1d4a3ce] \u001b[39m\u001b[92m+ BitFlags v0.1.9\u001b[39m\n",
      "  \u001b[90m[62783981] \u001b[39m\u001b[92m+ BitTwiddlingConvenienceFunctions v0.1.6\u001b[39m\n",
      "  \u001b[90m[fa961155] \u001b[39m\u001b[92m+ CEnum v0.5.0\u001b[39m\n",
      "  \u001b[90m[2a0fbf3d] \u001b[39m\u001b[92m+ CPUSummary v0.2.7\u001b[39m\n",
      "  \u001b[90m[336ed68f] \u001b[39m\u001b[92m+ CSV v0.10.16\u001b[39m\n",
      "  \u001b[90m[aafaddc9] \u001b[39m\u001b[92m+ CatIndices v0.2.2\u001b[39m\n",
      "  \u001b[90m[d360d2e6] \u001b[39m\u001b[92m+ ChainRulesCore v1.26.0\u001b[39m\n",
      "  \u001b[90m[0b6fb165] \u001b[39m\u001b[92m+ ChunkCodecCore v1.0.1\u001b[39m\n",
      "  \u001b[90m[4c0bbee4] \u001b[39m\u001b[92m+ ChunkCodecLibZlib v1.0.0\u001b[39m\n",
      "  \u001b[90m[55437552] \u001b[39m\u001b[92m+ ChunkCodecLibZstd v1.0.0\u001b[39m\n",
      "  \u001b[90m[fb6a15b2] \u001b[39m\u001b[92m+ CloseOpenIntervals v0.1.13\u001b[39m\n",
      "  \u001b[90m[aaaa29a8] \u001b[39m\u001b[92m+ Clustering v0.15.8\u001b[39m\n",
      "  \u001b[90m[523fee87] \u001b[39m\u001b[92m+ CodecBzip2 v0.8.5\u001b[39m\n",
      "  \u001b[90m[944b1d66] \u001b[39m\u001b[92m+ CodecZlib v0.7.8\u001b[39m\n",
      "  \u001b[90m[35d6a980] \u001b[39m\u001b[92m+ ColorSchemes v3.31.0\u001b[39m\n",
      "  \u001b[90m[3da002f7] \u001b[39m\u001b[92m+ ColorTypes v0.12.1\u001b[39m\n",
      "  \u001b[90m[c3611d14] \u001b[39m\u001b[92m+ ColorVectorSpace v0.11.0\u001b[39m\n",
      "  \u001b[90m[5ae59095] \u001b[39m\u001b[92m+ Colors v0.13.1\u001b[39m\n",
      "  \u001b[90m[bbf7d656] \u001b[39m\u001b[92m+ CommonSubexpressions v0.3.1\u001b[39m\n",
      "  \u001b[90m[f70d9fcc] \u001b[39m\u001b[92m+ CommonWorldInvalidations v1.0.0\u001b[39m\n",
      "  \u001b[90m[34da2185] \u001b[39m\u001b[92m+ Compat v4.18.1\u001b[39m\n",
      "  \u001b[90m[a33af91c] \u001b[39m\u001b[92m+ CompositionsBase v0.1.2\u001b[39m\n",
      "  \u001b[90m[ed09eef8] \u001b[39m\u001b[92m+ ComputationalResources v0.3.2\u001b[39m\n",
      "  \u001b[90m[f0e56b4a] \u001b[39m\u001b[92m+ ConcurrentUtilities v2.5.1\u001b[39m\n",
      "  \u001b[90m[8f4d0f93] \u001b[39m\u001b[92m+ Conda v1.10.3\u001b[39m\n",
      "  \u001b[90m[187b0558] \u001b[39m\u001b[92m+ ConstructionBase v1.6.0\u001b[39m\n",
      "  \u001b[90m[d38c429a] \u001b[39m\u001b[92m+ Contour v0.6.3\u001b[39m\n",
      "  \u001b[90m[150eb455] \u001b[39m\u001b[92m+ CoordinateTransformations v0.6.4\u001b[39m\n",
      "  \u001b[90m[adafc99b] \u001b[39m\u001b[92m+ CpuId v0.3.1\u001b[39m\n",
      "  \u001b[90m[a8cc5b0e] \u001b[39m\u001b[92m+ Crayons v4.1.1\u001b[39m\n",
      "  \u001b[90m[dc8bdbbb] \u001b[39m\u001b[92m+ CustomUnitRanges v1.0.2\u001b[39m\n",
      "  \u001b[90m[9a962f9c] \u001b[39m\u001b[92m+ DataAPI v1.16.0\u001b[39m\n",
      "  \u001b[90m[a93c6f00] \u001b[39m\u001b[92m+ DataFrames v1.8.1\u001b[39m\n",
      "  \u001b[90m[864edb3b] \u001b[39m\u001b[92m+ DataStructures v0.19.3\u001b[39m\n",
      "  \u001b[90m[e2d170a0] \u001b[39m\u001b[92m+ DataValueInterfaces v1.0.0\u001b[39m\n",
      "  \u001b[90m[8bb1440f] \u001b[39m\u001b[92m+ DelimitedFiles v1.9.1\u001b[39m\n",
      "  \u001b[90m[163ba53b] \u001b[39m\u001b[92m+ DiffResults v1.1.0\u001b[39m\n",
      "  \u001b[90m[b552c78f] \u001b[39m\u001b[92m+ DiffRules v1.15.1\u001b[39m\n",
      "  \u001b[90m[b4f34e82] \u001b[39m\u001b[92m+ Distances v0.10.12\u001b[39m\n",
      "  \u001b[90m[31c24e10] \u001b[39m\u001b[92m+ Distributions v0.25.123\u001b[39m\n",
      "  \u001b[90m[ffbed154] \u001b[39m\u001b[92m+ DocStringExtensions v0.9.5\u001b[39m\n",
      "  \u001b[90m[460bff9d] \u001b[39m\u001b[92m+ ExceptionUnwrapping v0.1.11\u001b[39m\n",
      "  \u001b[90m[e2ba6199] \u001b[39m\u001b[92m+ ExprTools v0.1.10\u001b[39m\n",
      "  \u001b[90m[c87230d0] \u001b[39m\u001b[92m+ FFMPEG v0.4.5\u001b[39m\n",
      "  \u001b[90m[b86e33f2] \u001b[39m\u001b[92m+ FFTA v0.3.1\u001b[39m\n",
      "  \u001b[90m[4f61f5a4] \u001b[39m\u001b[92m+ FFTViews v0.3.2\u001b[39m\n",
      "  \u001b[90m[7a1cc6ca] \u001b[39m\u001b[92m+ FFTW v1.10.0\u001b[39m\n",
      "  \u001b[90m[9aa1b823] \u001b[39m\u001b[92m+ FastClosures v0.3.2\u001b[39m\n",
      "  \u001b[90m[5789e2e9] \u001b[39m\u001b[92m+ FileIO v1.18.0\u001b[39m\n",
      "  \u001b[90m[48062228] \u001b[39m\u001b[92m+ FilePathsBase v0.9.24\u001b[39m\n",
      "  \u001b[90m[1a297f60] \u001b[39m\u001b[92m+ FillArrays v1.16.0\u001b[39m\n",
      "  \u001b[90m[53c48c17] \u001b[39m\u001b[92m+ FixedPointNumbers v0.8.5\u001b[39m\n",
      "  \u001b[90m[1fa38f19] \u001b[39m\u001b[92m+ Format v1.3.7\u001b[39m\n",
      "  \u001b[90m[f6369f11] \u001b[39m\u001b[92m+ ForwardDiff v1.3.2\u001b[39m\n",
      "  \u001b[90m[d9f16b24] \u001b[39m\u001b[92m+ Functors v0.5.2\u001b[39m\n",
      "  \u001b[90m[60bf3e95] \u001b[39m\u001b[92m+ GLPK v1.2.1\u001b[39m\n",
      "  \u001b[90m[46192b85] \u001b[39m\u001b[92m+ GPUArraysCore v0.2.0\u001b[39m\n",
      "  \u001b[90m[28b8d3ca] \u001b[39m\u001b[92m+ GR v0.73.22\u001b[39m\n",
      "  \u001b[90m[a2bd30eb] \u001b[39m\u001b[92m+ Graphics v1.1.3\u001b[39m\n",
      "  \u001b[90m[86223c79] \u001b[39m\u001b[92m+ Graphs v1.14.0\u001b[39m\n",
      "  \u001b[90m[42e2da0e] \u001b[39m\u001b[92m+ Grisu v1.0.2\u001b[39m\n",
      "  \u001b[90m[cd3eb016] \u001b[39m\u001b[92m+ HTTP v1.10.19\u001b[39m\n",
      "  \u001b[90m[076d061b] \u001b[39m\u001b[92m+ HashArrayMappedTries v0.2.0\u001b[39m\n",
      "  \u001b[90m[2c695a8d] \u001b[39m\u001b[92m+ HistogramThresholding v0.3.1\u001b[39m\n",
      "  \u001b[90m[3e5b6fbb] \u001b[39m\u001b[92m+ HostCPUFeatures v0.1.18\u001b[39m\n",
      "  \u001b[90m[34004b35] \u001b[39m\u001b[92m+ HypergeometricFunctions v0.3.28\u001b[39m\n",
      "  \u001b[90m[7073ff75] \u001b[39m\u001b[92m+ IJulia v1.34.4\u001b[39m\n",
      "  \u001b[90m[615f187c] \u001b[39m\u001b[92m+ IfElse v0.1.1\u001b[39m\n",
      "  \u001b[90m[2803e5a7] \u001b[39m\u001b[92m+ ImageAxes v0.6.12\u001b[39m\n",
      "  \u001b[90m[c817782e] \u001b[39m\u001b[92m+ ImageBase v0.1.7\u001b[39m\n",
      "  \u001b[90m[cbc4b850] \u001b[39m\u001b[92m+ ImageBinarization v0.3.1\u001b[39m\n",
      "  \u001b[90m[f332f351] \u001b[39m\u001b[92m+ ImageContrastAdjustment v0.3.12\u001b[39m\n",
      "  \u001b[90m[a09fc81d] \u001b[39m\u001b[92m+ ImageCore v0.10.5\u001b[39m\n",
      "  \u001b[90m[89d5987c] \u001b[39m\u001b[92m+ ImageCorners v0.1.3\u001b[39m\n",
      "  \u001b[90m[51556ac3] \u001b[39m\u001b[92m+ ImageDistances v0.2.17\u001b[39m\n",
      "  \u001b[90m[6a3955dd] \u001b[39m\u001b[92m+ ImageFiltering v0.7.12\u001b[39m\n",
      "  \u001b[90m[82e4d734] \u001b[39m\u001b[92m+ ImageIO v0.6.9\u001b[39m\n",
      "  \u001b[90m[6218d12a] \u001b[39m\u001b[92m+ ImageMagick v1.4.2\u001b[39m\n",
      "  \u001b[90m[bc367c6b] \u001b[39m\u001b[92m+ ImageMetadata v0.9.10\u001b[39m\n",
      "  \u001b[90m[787d08f9] \u001b[39m\u001b[92m+ ImageMorphology v0.4.7\u001b[39m\n",
      "  \u001b[90m[2996bd0c] \u001b[39m\u001b[92m+ ImageQualityIndexes v0.3.7\u001b[39m\n",
      "  \u001b[90m[80713f31] \u001b[39m\u001b[92m+ ImageSegmentation v1.10.0\u001b[39m\n",
      "  \u001b[90m[4e3cecfd] \u001b[39m\u001b[92m+ ImageShow v0.3.8\u001b[39m\n",
      "  \u001b[90m[02fcd773] \u001b[39m\u001b[92m+ ImageTransformations v0.10.2\u001b[39m\n",
      "  \u001b[90m[916415d5] \u001b[39m\u001b[92m+ Images v0.26.2\u001b[39m\n",
      "  \u001b[90m[9b13fd28] \u001b[39m\u001b[92m+ IndirectArrays v1.0.0\u001b[39m\n",
      "  \u001b[90m[d25df0c9] \u001b[39m\u001b[92m+ Inflate v0.1.5\u001b[39m\n",
      "  \u001b[90m[842dd82b] \u001b[39m\u001b[92m+ InlineStrings v1.4.5\u001b[39m\n",
      "  \u001b[90m[18e54dd8] \u001b[39m\u001b[92m+ IntegerMathUtils v0.1.3\u001b[39m\n",
      "  \u001b[90m[1d092043] \u001b[39m\u001b[92m+ IntegralArrays v0.1.6\u001b[39m\n",
      "  \u001b[90m[a98d9a8b] \u001b[39m\u001b[92m+ Interpolations v0.16.2\u001b[39m\n",
      "  \u001b[90m[8197267c] \u001b[39m\u001b[92m+ IntervalSets v0.7.13\u001b[39m\n",
      "  \u001b[90m[41ab1584] \u001b[39m\u001b[92m+ InvertedIndices v1.3.1\u001b[39m\n",
      "  \u001b[90m[92d709cd] \u001b[39m\u001b[92m+ IrrationalConstants v0.2.6\u001b[39m\n",
      "  \u001b[90m[c8e1da08] \u001b[39m\u001b[92m+ IterTools v1.10.0\u001b[39m\n",
      "  \u001b[90m[82899510] \u001b[39m\u001b[92m+ IteratorInterfaceExtensions v1.0.0\u001b[39m\n",
      "  \u001b[90m[033835bb] \u001b[39m\u001b[92m+ JLD2 v0.6.3\u001b[39m\n",
      "  \u001b[90m[1019f520] \u001b[39m\u001b[92m+ JLFzf v0.1.11\u001b[39m\n",
      "  \u001b[90m[692b3bcd] \u001b[39m\u001b[92m+ JLLWrappers v1.7.1\u001b[39m\n",
      "  \u001b[90m[682c06a0] \u001b[39m\u001b[92m+ JSON v1.4.0\u001b[39m\n",
      "  \u001b[90m[b835a17e] \u001b[39m\u001b[92m+ JpegTurbo v0.1.6\u001b[39m\n",
      "  \u001b[90m[4076af6c] \u001b[39m\u001b[92m+ JuMP v1.29.4\u001b[39m\n",
      "  \u001b[90m[63c18a36] \u001b[39m\u001b[92m+ KernelAbstractions v0.9.40\u001b[39m\n",
      "  \u001b[90m[5ab0869b] \u001b[39m\u001b[92m+ KernelDensity v0.6.11\u001b[39m\n",
      "  \u001b[90m[ec8451be] \u001b[39m\u001b[92m+ KernelFunctions v0.10.67\u001b[39m\n",
      "  \u001b[90m[40e66cde] \u001b[39m\u001b[92m+ LDLFactorizations v0.10.1\u001b[39m\n",
      "  \u001b[90m[b964fa9f] \u001b[39m\u001b[92m+ LaTeXStrings v1.4.0\u001b[39m\n",
      "  \u001b[90m[23fbe1c1] \u001b[39m\u001b[92m+ Latexify v0.16.10\u001b[39m\n",
      "  \u001b[90m[10f19ff3] \u001b[39m\u001b[92m+ LayoutPointers v0.1.17\u001b[39m\n",
      "  \u001b[90m[8cdb02fc] \u001b[39m\u001b[92m+ LazyModules v0.3.1\u001b[39m\n",
      "  \u001b[90m[5c8ed15e] \u001b[39m\u001b[92m+ LinearOperators v2.13.0\u001b[39m\n",
      "  \u001b[90m[2ab3a3ac] \u001b[39m\u001b[92m+ LogExpFunctions v0.3.29\u001b[39m\n",
      "  \u001b[90m[e6f89c97] \u001b[39m\u001b[92m+ LoggingExtras v1.2.0\u001b[39m\n",
      "  \u001b[90m[bdcacae8] \u001b[39m\u001b[92m+ LoopVectorization v0.12.173\u001b[39m\n",
      "  \u001b[90m[1914dd2f] \u001b[39m\u001b[92m+ MacroTools v0.5.16\u001b[39m\n",
      "\u001b[32m⌃\u001b[39m \u001b[90m[2621e9c9] \u001b[39m\u001b[92m+ MadNLP v0.8.12\u001b[39m\n",
      "  \u001b[90m[d125e4d3] \u001b[39m\u001b[92m+ ManualMemory v0.1.8\u001b[39m\n",
      "  \u001b[90m[dbb5928d] \u001b[39m\u001b[92m+ MappedArrays v0.4.3\u001b[39m\n",
      "  \u001b[90m[b8f27783] \u001b[39m\u001b[92m+ MathOptInterface v1.49.0\u001b[39m\n",
      "  \u001b[90m[739be429] \u001b[39m\u001b[92m+ MbedTLS v1.1.10\u001b[39m\n",
      "  \u001b[90m[442fdcdd] \u001b[39m\u001b[92m+ Measures v0.3.3\u001b[39m\n",
      "\u001b[33m⌅\u001b[39m \u001b[90m[626554b9] \u001b[39m\u001b[92m+ MetaGraphs v0.8.1\u001b[39m\n",
      "  \u001b[90m[e1d29d7a] \u001b[39m\u001b[92m+ Missings v1.2.0\u001b[39m\n",
      "  \u001b[90m[e94cdb99] \u001b[39m\u001b[92m+ MosaicViews v0.3.4\u001b[39m\n",
      "  \u001b[90m[46d2c3a1] \u001b[39m\u001b[92m+ MuladdMacro v0.2.4\u001b[39m\n",
      "  \u001b[90m[6f286f6a] \u001b[39m\u001b[92m+ MultivariateStats v0.10.4\u001b[39m\n",
      "  \u001b[90m[d8a4904e] \u001b[39m\u001b[92m+ MutableArithmetics v1.6.7\u001b[39m\n",
      "  \u001b[90m[a4795742] \u001b[39m\u001b[92m+ NLPModels v0.21.11\u001b[39m\n",
      "  \u001b[90m[872c559c] \u001b[39m\u001b[92m+ NNlib v0.9.33\u001b[39m\n",
      "  \u001b[90m[77ba4419] \u001b[39m\u001b[92m+ NaNMath v1.1.3\u001b[39m\n",
      "  \u001b[90m[b8a86587] \u001b[39m\u001b[92m+ NearestNeighbors v0.4.27\u001b[39m\n",
      "  \u001b[90m[f09324ee] \u001b[39m\u001b[92m+ Netpbm v1.1.1\u001b[39m\n",
      "  \u001b[90m[510215fc] \u001b[39m\u001b[92m+ Observables v0.5.5\u001b[39m\n",
      "  \u001b[90m[6fe1bfb0] \u001b[39m\u001b[92m+ OffsetArrays v1.17.0\u001b[39m\n",
      "  \u001b[90m[52e1d378] \u001b[39m\u001b[92m+ OpenEXR v0.3.3\u001b[39m\n",
      "  \u001b[90m[4d8831e6] \u001b[39m\u001b[92m+ OpenSSL v1.6.1\u001b[39m\n",
      "  \u001b[90m[bac558e1] \u001b[39m\u001b[92m+ OrderedCollections v1.8.1\u001b[39m\n",
      "  \u001b[90m[90014a1f] \u001b[39m\u001b[92m+ PDMats v0.11.37\u001b[39m\n",
      "  \u001b[90m[f57f5aa1] \u001b[39m\u001b[92m+ PNGFiles v0.4.4\u001b[39m\n",
      "  \u001b[90m[5432bcbf] \u001b[39m\u001b[92m+ PaddedViews v0.5.12\u001b[39m\n",
      "  \u001b[90m[d96e819e] \u001b[39m\u001b[92m+ Parameters v0.12.3\u001b[39m\n",
      "  \u001b[90m[69de0a69] \u001b[39m\u001b[92m+ Parsers v2.8.3\u001b[39m\n",
      "  \u001b[90m[eebad327] \u001b[39m\u001b[92m+ PkgVersion v0.3.3\u001b[39m\n",
      "  \u001b[90m[ccf2f8ad] \u001b[39m\u001b[92m+ PlotThemes v3.3.0\u001b[39m\n",
      "  \u001b[90m[995b91a9] \u001b[39m\u001b[92m+ PlotUtils v1.4.4\u001b[39m\n",
      "  \u001b[90m[91a5bcdd] \u001b[39m\u001b[92m+ Plots v1.41.6\u001b[39m\n",
      "  \u001b[90m[1d0040c9] \u001b[39m\u001b[92m+ PolyesterWeave v0.2.2\u001b[39m\n",
      "  \u001b[90m[f27b6e38] \u001b[39m\u001b[92m+ Polynomials v4.1.0\u001b[39m\n",
      "  \u001b[90m[2dfb63ee] \u001b[39m\u001b[92m+ PooledArrays v1.4.3\u001b[39m\n",
      "  \u001b[90m[aea7be01] \u001b[39m\u001b[92m+ PrecompileTools v1.3.3\u001b[39m\n",
      "  \u001b[90m[21216c6a] \u001b[39m\u001b[92m+ Preferences v1.5.2\u001b[39m\n",
      "  \u001b[90m[08abe8d2] \u001b[39m\u001b[92m+ PrettyTables v3.2.3\u001b[39m\n",
      "  \u001b[90m[27ebfcd6] \u001b[39m\u001b[92m+ Primes v0.5.7\u001b[39m\n",
      "  \u001b[90m[92933f4c] \u001b[39m\u001b[92m+ ProgressMeter v1.11.0\u001b[39m\n",
      "  \u001b[90m[43287f4e] \u001b[39m\u001b[92m+ PtrArrays v1.4.0\u001b[39m\n",
      "  \u001b[90m[4b34888f] \u001b[39m\u001b[92m+ QOI v1.0.2\u001b[39m\n",
      "  \u001b[90m[1fd47b50] \u001b[39m\u001b[92m+ QuadGK v2.11.2\u001b[39m\n",
      "  \u001b[90m[94ee1d12] \u001b[39m\u001b[92m+ Quaternions v0.7.7\u001b[39m\n",
      "  \u001b[90m[b3c3ace0] \u001b[39m\u001b[92m+ RangeArrays v0.3.2\u001b[39m\n",
      "  \u001b[90m[c84ed2f1] \u001b[39m\u001b[92m+ Ratios v0.4.5\u001b[39m\n",
      "  \u001b[90m[c1ae055f] \u001b[39m\u001b[92m+ RealDot v0.1.0\u001b[39m\n",
      "  \u001b[90m[3cdcf5f2] \u001b[39m\u001b[92m+ RecipesBase v1.3.4\u001b[39m\n",
      "  \u001b[90m[01d81517] \u001b[39m\u001b[92m+ RecipesPipeline v0.6.12\u001b[39m\n",
      "  \u001b[90m[189a3867] \u001b[39m\u001b[92m+ Reexport v1.2.2\u001b[39m\n",
      "  \u001b[90m[dee08c22] \u001b[39m\u001b[92m+ RegionTrees v0.3.2\u001b[39m\n",
      "  \u001b[90m[05181044] \u001b[39m\u001b[92m+ RelocatableFolders v1.0.1\u001b[39m\n",
      "  \u001b[90m[ae029012] \u001b[39m\u001b[92m+ Requires v1.3.1\u001b[39m\n",
      "  \u001b[90m[79098fc4] \u001b[39m\u001b[92m+ Rmath v0.9.0\u001b[39m\n",
      "  \u001b[90m[6038ab10] \u001b[39m\u001b[92m+ Rotations v1.7.1\u001b[39m\n",
      "  \u001b[90m[fdea26ae] \u001b[39m\u001b[92m+ SIMD v3.7.2\u001b[39m\n",
      "  \u001b[90m[94e857df] \u001b[39m\u001b[92m+ SIMDTypes v0.1.0\u001b[39m\n",
      "  \u001b[90m[476501e8] \u001b[39m\u001b[92m+ SLEEFPirates v0.6.43\u001b[39m\n",
      "  \u001b[90m[431bcebd] \u001b[39m\u001b[92m+ SciMLPublic v1.0.1\u001b[39m\n",
      "  \u001b[90m[7e506255] \u001b[39m\u001b[92m+ ScopedValues v1.5.0\u001b[39m\n",
      "  \u001b[90m[6c6a2e73] \u001b[39m\u001b[92m+ Scratch v1.3.0\u001b[39m\n",
      "  \u001b[90m[91c51154] \u001b[39m\u001b[92m+ SentinelArrays v1.4.9\u001b[39m\n",
      "  \u001b[90m[efcf1570] \u001b[39m\u001b[92m+ Setfield v1.1.2\u001b[39m\n",
      "  \u001b[90m[992d4aef] \u001b[39m\u001b[92m+ Showoff v1.0.3\u001b[39m\n",
      "  \u001b[90m[777ac1f9] \u001b[39m\u001b[92m+ SimpleBufferStream v1.2.0\u001b[39m\n",
      "  \u001b[90m[699a6c99] \u001b[39m\u001b[92m+ SimpleTraits v0.9.5\u001b[39m\n",
      "  \u001b[90m[47aef6b3] \u001b[39m\u001b[92m+ SimpleWeightedGraphs v1.5.1\u001b[39m\n",
      "  \u001b[90m[45858cf5] \u001b[39m\u001b[92m+ Sixel v0.1.5\u001b[39m\n",
      "  \u001b[90m[ff4d7338] \u001b[39m\u001b[92m+ SolverCore v0.3.10\u001b[39m\n",
      "  \u001b[90m[a2af1166] \u001b[39m\u001b[92m+ SortingAlgorithms v1.2.2\u001b[39m\n",
      "  \u001b[90m[276daf66] \u001b[39m\u001b[92m+ SpecialFunctions v2.7.1\u001b[39m\n",
      "  \u001b[90m[860ef19b] \u001b[39m\u001b[92m+ StableRNGs v1.0.4\u001b[39m\n",
      "  \u001b[90m[cae243ae] \u001b[39m\u001b[92m+ StackViews v0.1.2\u001b[39m\n",
      "  \u001b[90m[aedffcd0] \u001b[39m\u001b[92m+ Static v1.3.1\u001b[39m\n",
      "  \u001b[90m[0d7ed370] \u001b[39m\u001b[92m+ StaticArrayInterface v1.9.0\u001b[39m\n",
      "  \u001b[90m[90137ffa] \u001b[39m\u001b[92m+ StaticArrays v1.9.17\u001b[39m\n",
      "  \u001b[90m[1e83bf80] \u001b[39m\u001b[92m+ StaticArraysCore v1.4.4\u001b[39m\n",
      "  \u001b[90m[10745b16] \u001b[39m\u001b[92m+ Statistics v1.11.1\u001b[39m\n",
      "  \u001b[90m[82ae8749] \u001b[39m\u001b[92m+ StatsAPI v1.8.0\u001b[39m\n",
      "  \u001b[90m[2913bbd2] \u001b[39m\u001b[92m+ StatsBase v0.34.10\u001b[39m\n",
      "  \u001b[90m[4c63d2b9] \u001b[39m\u001b[92m+ StatsFuns v1.5.2\u001b[39m\n",
      "  \u001b[90m[f3b207a7] \u001b[39m\u001b[92m+ StatsPlots v0.15.8\u001b[39m\n",
      "  \u001b[90m[892a3eda] \u001b[39m\u001b[92m+ StringManipulation v0.4.4\u001b[39m\n",
      "  \u001b[90m[ec057cc2] \u001b[39m\u001b[92m+ StructUtils v2.6.3\u001b[39m\n",
      "  \u001b[90m[ab02a1b2] \u001b[39m\u001b[92m+ TableOperations v1.2.0\u001b[39m\n",
      "  \u001b[90m[3783bdb8] \u001b[39m\u001b[92m+ TableTraits v1.0.1\u001b[39m\n",
      "  \u001b[90m[bd369af6] \u001b[39m\u001b[92m+ Tables v1.12.1\u001b[39m\n",
      "  \u001b[90m[62fd8b95] \u001b[39m\u001b[92m+ TensorCore v0.1.1\u001b[39m\n",
      "  \u001b[90m[8290d209] \u001b[39m\u001b[92m+ ThreadingUtilities v0.5.5\u001b[39m\n",
      "  \u001b[90m[731e570b] \u001b[39m\u001b[92m+ TiffImages v0.11.6\u001b[39m\n",
      "  \u001b[90m[06e1c1a7] \u001b[39m\u001b[92m+ TiledIteration v0.5.0\u001b[39m\n",
      "  \u001b[90m[a759f4b9] \u001b[39m\u001b[92m+ TimerOutputs v0.5.29\u001b[39m\n",
      "  \u001b[90m[3bb67fe8] \u001b[39m\u001b[92m+ TranscodingStreams v0.11.3\u001b[39m\n",
      "  \u001b[90m[5c2747f8] \u001b[39m\u001b[92m+ URIs v1.6.1\u001b[39m\n",
      "  \u001b[90m[3a884ed6] \u001b[39m\u001b[92m+ UnPack v1.0.2\u001b[39m\n",
      "  \u001b[90m[1cfade01] \u001b[39m\u001b[92m+ UnicodeFun v0.4.1\u001b[39m\n",
      "  \u001b[90m[013be700] \u001b[39m\u001b[92m+ UnsafeAtomics v0.3.0\u001b[39m\n",
      "  \u001b[90m[41fe7b60] \u001b[39m\u001b[92m+ Unzip v0.2.0\u001b[39m\n",
      "  \u001b[90m[24b76065] \u001b[39m\u001b[92m+ VLDataScienceMachineLearningPackage v0.1.0 `https://github.com/varnerlab/VLDataScienceMachineLearningPackage.jl.git#main`\u001b[39m\n",
      "  \u001b[90m[3d5dd08c] \u001b[39m\u001b[92m+ VectorizationBase v0.21.72\u001b[39m\n",
      "  \u001b[90m[81def892] \u001b[39m\u001b[92m+ VersionParsing v1.3.0\u001b[39m\n",
      "  \u001b[90m[ea10d353] \u001b[39m\u001b[92m+ WeakRefStrings v1.4.2\u001b[39m\n",
      "  \u001b[90m[e3aaa7dc] \u001b[39m\u001b[92m+ WebP v0.1.3\u001b[39m\n",
      "  \u001b[90m[cc8bc4a8] \u001b[39m\u001b[92m+ Widgets v0.6.7\u001b[39m\n",
      "  \u001b[90m[efce3f68] \u001b[39m\u001b[92m+ WoodburyMatrices v1.1.0\u001b[39m\n",
      "  \u001b[90m[76eceee3] \u001b[39m\u001b[92m+ WorkerUtilities v1.6.1\u001b[39m\n",
      "  \u001b[90m[c2297ded] \u001b[39m\u001b[92m+ ZMQ v1.5.1\u001b[39m\n",
      "  \u001b[90m[700de1a5] \u001b[39m\u001b[92m+ ZygoteRules v0.2.7\u001b[39m\n",
      "\u001b[33m⌅\u001b[39m \u001b[90m[68821587] \u001b[39m\u001b[92m+ Arpack_jll v3.5.2+0\u001b[39m\n",
      "  \u001b[90m[6e34b625] \u001b[39m\u001b[92m+ Bzip2_jll v1.0.9+0\u001b[39m\n",
      "  \u001b[90m[83423d85] \u001b[39m\u001b[92m+ Cairo_jll v1.18.5+1\u001b[39m\n",
      "  \u001b[90m[ee1fde0b] \u001b[39m\u001b[92m+ Dbus_jll v1.16.2+0\u001b[39m\n",
      "  \u001b[90m[2702e6a9] \u001b[39m\u001b[92m+ EpollShim_jll v0.0.20230411+1\u001b[39m\n",
      "  \u001b[90m[2e619515] \u001b[39m\u001b[92m+ Expat_jll v2.7.3+0\u001b[39m\n",
      "  \u001b[90m[b22a6f82] \u001b[39m\u001b[92m+ FFMPEG_jll v8.0.1+0\u001b[39m\n",
      "  \u001b[90m[f5851436] \u001b[39m\u001b[92m+ FFTW_jll v3.3.11+0\u001b[39m\n",
      "  \u001b[90m[a3f928ae] \u001b[39m\u001b[92m+ Fontconfig_jll v2.17.1+0\u001b[39m\n",
      "  \u001b[90m[d7e528f0] \u001b[39m\u001b[92m+ FreeType2_jll v2.13.4+0\u001b[39m\n",
      "  \u001b[90m[559328eb] \u001b[39m\u001b[92m+ FriBidi_jll v1.0.17+0\u001b[39m\n",
      "  \u001b[90m[0656b61e] \u001b[39m\u001b[92m+ GLFW_jll v3.4.1+0\u001b[39m\n",
      "  \u001b[90m[e8aa6df9] \u001b[39m\u001b[92m+ GLPK_jll v5.0.1+1\u001b[39m\n",
      "  \u001b[90m[d2c73de3] \u001b[39m\u001b[92m+ GR_jll v0.73.22+0\u001b[39m\n",
      "  \u001b[90m[b0724c58] \u001b[39m\u001b[92m+ GettextRuntime_jll v0.22.4+0\u001b[39m\n",
      "  \u001b[90m[61579ee1] \u001b[39m\u001b[92m+ Ghostscript_jll v9.55.1+0\u001b[39m\n",
      "  \u001b[90m[59f7168a] \u001b[39m\u001b[92m+ Giflib_jll v5.2.3+0\u001b[39m\n",
      "  \u001b[90m[7746bdde] \u001b[39m\u001b[92m+ Glib_jll v2.86.3+0\u001b[39m\n",
      "  \u001b[90m[3b182d85] \u001b[39m\u001b[92m+ Graphite2_jll v1.3.15+0\u001b[39m\n",
      "  \u001b[90m[2e76f6c2] \u001b[39m\u001b[92m+ HarfBuzz_jll v8.5.1+0\u001b[39m\n",
      "  \u001b[90m[c73af94c] \u001b[39m\u001b[92m+ ImageMagick_jll v7.1.2011+0\u001b[39m\n",
      "  \u001b[90m[905a6f67] \u001b[39m\u001b[92m+ Imath_jll v3.2.2+0\u001b[39m\n",
      "  \u001b[90m[1d5cc7b8] \u001b[39m\u001b[92m+ IntelOpenMP_jll v2025.2.0+0\u001b[39m\n",
      "  \u001b[90m[aacddb02] \u001b[39m\u001b[92m+ JpegTurbo_jll v3.1.4+0\u001b[39m\n",
      "  \u001b[90m[c1c5ebd0] \u001b[39m\u001b[92m+ LAME_jll v3.100.3+0\u001b[39m\n",
      "  \u001b[90m[88015f11] \u001b[39m\u001b[92m+ LERC_jll v4.0.1+0\u001b[39m\n",
      "  \u001b[90m[1d63c593] \u001b[39m\u001b[92m+ LLVMOpenMP_jll v18.1.8+0\u001b[39m\n",
      "  \u001b[90m[dd4b983a] \u001b[39m\u001b[92m+ LZO_jll v2.10.3+0\u001b[39m\n",
      "\u001b[33m⌅\u001b[39m \u001b[90m[e9f186c6] \u001b[39m\u001b[92m+ Libffi_jll v3.4.7+0\u001b[39m\n",
      "  \u001b[90m[7e76a0d4] \u001b[39m\u001b[92m+ Libglvnd_jll v1.7.1+1\u001b[39m\n",
      "  \u001b[90m[94ce4f54] \u001b[39m\u001b[92m+ Libiconv_jll v1.18.0+0\u001b[39m\n",
      "  \u001b[90m[4b2f31a3] \u001b[39m\u001b[92m+ Libmount_jll v2.41.3+0\u001b[39m\n",
      "  \u001b[90m[89763e89] \u001b[39m\u001b[92m+ Libtiff_jll v4.7.2+0\u001b[39m\n",
      "  \u001b[90m[38a345b3] \u001b[39m\u001b[92m+ Libuuid_jll v2.41.3+0\u001b[39m\n",
      "  \u001b[90m[d3a379c0] \u001b[39m\u001b[92m+ LittleCMS_jll v2.17.0+0\u001b[39m\n",
      "  \u001b[90m[856f044c] \u001b[39m\u001b[92m+ MKL_jll v2025.2.0+0\u001b[39m\n",
      "  \u001b[90m[c8ffd9c3] \u001b[39m\u001b[92m+ MbedTLS_jll v2.28.1010+0\u001b[39m\n",
      "  \u001b[90m[e7412a2a] \u001b[39m\u001b[92m+ Ogg_jll v1.3.6+0\u001b[39m\n",
      "  \u001b[90m[18a262bb] \u001b[39m\u001b[92m+ OpenEXR_jll v3.4.4+0\u001b[39m\n",
      "  \u001b[90m[643b3616] \u001b[39m\u001b[92m+ OpenJpeg_jll v2.5.5+0\u001b[39m\n",
      "  \u001b[90m[efe28fd5] \u001b[39m\u001b[92m+ OpenSpecFun_jll v0.5.6+0\u001b[39m\n",
      "  \u001b[90m[91d4177d] \u001b[39m\u001b[92m+ Opus_jll v1.6.1+0\u001b[39m\n",
      "  \u001b[90m[36c8627f] \u001b[39m\u001b[92m+ Pango_jll v1.57.0+0\u001b[39m\n",
      "\u001b[33m⌅\u001b[39m \u001b[90m[30392449] \u001b[39m\u001b[92m+ Pixman_jll v0.44.2+0\u001b[39m\n",
      "\u001b[33m⌅\u001b[39m \u001b[90m[c0090381] \u001b[39m\u001b[92m+ Qt6Base_jll v6.8.2+2\u001b[39m\n",
      "\u001b[33m⌅\u001b[39m \u001b[90m[629bc702] \u001b[39m\u001b[92m+ Qt6Declarative_jll v6.8.2+1\u001b[39m\n",
      "\u001b[33m⌅\u001b[39m \u001b[90m[ce943373] \u001b[39m\u001b[92m+ Qt6ShaderTools_jll v6.8.2+1\u001b[39m\n",
      "\u001b[32m⌃\u001b[39m \u001b[90m[e99dba38] \u001b[39m\u001b[92m+ Qt6Wayland_jll v6.8.2+2\u001b[39m\n",
      "  \u001b[90m[f50d1b31] \u001b[39m\u001b[92m+ Rmath_jll v0.5.1+0\u001b[39m\n",
      "  \u001b[90m[a44049a8] \u001b[39m\u001b[92m+ Vulkan_Loader_jll v1.3.243+0\u001b[39m\n",
      "  \u001b[90m[a2964d1f] \u001b[39m\u001b[92m+ Wayland_jll v1.24.0+0\u001b[39m\n",
      "  \u001b[90m[ffd25f8a] \u001b[39m\u001b[92m+ XZ_jll v5.8.2+0\u001b[39m\n",
      "  \u001b[90m[f67eecfb] \u001b[39m\u001b[92m+ Xorg_libICE_jll v1.1.2+0\u001b[39m\n",
      "  \u001b[90m[c834827a] \u001b[39m\u001b[92m+ Xorg_libSM_jll v1.2.6+0\u001b[39m\n",
      "  \u001b[90m[4f6342f7] \u001b[39m\u001b[92m+ Xorg_libX11_jll v1.8.13+0\u001b[39m\n",
      "  \u001b[90m[0c0b7dd1] \u001b[39m\u001b[92m+ Xorg_libXau_jll v1.0.13+0\u001b[39m\n",
      "  \u001b[90m[935fb764] \u001b[39m\u001b[92m+ Xorg_libXcursor_jll v1.2.4+0\u001b[39m\n",
      "  \u001b[90m[a3789734] \u001b[39m\u001b[92m+ Xorg_libXdmcp_jll v1.1.6+0\u001b[39m\n",
      "  \u001b[90m[1082639a] \u001b[39m\u001b[92m+ Xorg_libXext_jll v1.3.8+0\u001b[39m\n",
      "  \u001b[90m[d091e8ba] \u001b[39m\u001b[92m+ Xorg_libXfixes_jll v6.0.2+0\u001b[39m\n",
      "  \u001b[90m[a51aa0fd] \u001b[39m\u001b[92m+ Xorg_libXi_jll v1.8.3+0\u001b[39m\n",
      "  \u001b[90m[d1454406] \u001b[39m\u001b[92m+ Xorg_libXinerama_jll v1.1.7+0\u001b[39m\n",
      "  \u001b[90m[ec84b674] \u001b[39m\u001b[92m+ Xorg_libXrandr_jll v1.5.6+0\u001b[39m\n",
      "  \u001b[90m[ea2f1a96] \u001b[39m\u001b[92m+ Xorg_libXrender_jll v0.9.12+0\u001b[39m\n",
      "  \u001b[90m[c7cfdc94] \u001b[39m\u001b[92m+ Xorg_libxcb_jll v1.17.1+0\u001b[39m\n",
      "  \u001b[90m[cc61e674] \u001b[39m\u001b[92m+ Xorg_libxkbfile_jll v1.2.0+0\u001b[39m\n",
      "  \u001b[90m[e920d4aa] \u001b[39m\u001b[92m+ Xorg_xcb_util_cursor_jll v0.1.6+0\u001b[39m\n",
      "  \u001b[90m[12413925] \u001b[39m\u001b[92m+ Xorg_xcb_util_image_jll v0.4.1+0\u001b[39m\n",
      "  \u001b[90m[2def613f] \u001b[39m\u001b[92m+ Xorg_xcb_util_jll v0.4.1+0\u001b[39m\n",
      "  \u001b[90m[975044d2] \u001b[39m\u001b[92m+ Xorg_xcb_util_keysyms_jll v0.4.1+0\u001b[39m\n",
      "  \u001b[90m[0d47668e] \u001b[39m\u001b[92m+ Xorg_xcb_util_renderutil_jll v0.3.10+0\u001b[39m\n",
      "  \u001b[90m[c22f9ab0] \u001b[39m\u001b[92m+ Xorg_xcb_util_wm_jll v0.4.2+0\u001b[39m\n",
      "  \u001b[90m[35661453] \u001b[39m\u001b[92m+ Xorg_xkbcomp_jll v1.4.7+0\u001b[39m\n",
      "  \u001b[90m[33bec58e] \u001b[39m\u001b[92m+ Xorg_xkeyboard_config_jll v2.44.0+0\u001b[39m\n",
      "  \u001b[90m[c5fb5394] \u001b[39m\u001b[92m+ Xorg_xtrans_jll v1.6.0+0\u001b[39m\n",
      "  \u001b[90m[8f1865be] \u001b[39m\u001b[92m+ ZeroMQ_jll v4.3.6+0\u001b[39m\n",
      "  \u001b[90m[3161d3a3] \u001b[39m\u001b[92m+ Zstd_jll v1.5.7+1\u001b[39m\n",
      "  \u001b[90m[35ca27e7] \u001b[39m\u001b[92m+ eudev_jll v3.2.14+0\u001b[39m\n",
      "  \u001b[90m[214eeab7] \u001b[39m\u001b[92m+ fzf_jll v0.61.1+0\u001b[39m\n",
      "  \u001b[90m[a4ae2306] \u001b[39m\u001b[92m+ libaom_jll v3.13.1+0\u001b[39m\n",
      "  \u001b[90m[0ac62f75] \u001b[39m\u001b[92m+ libass_jll v0.17.4+0\u001b[39m\n",
      "  \u001b[90m[1183f4f0] \u001b[39m\u001b[92m+ libdecor_jll v0.2.2+0\u001b[39m\n",
      "  \u001b[90m[2db6ffa8] \u001b[39m\u001b[92m+ libevdev_jll v1.13.4+0\u001b[39m\n",
      "  \u001b[90m[f638f0a6] \u001b[39m\u001b[92m+ libfdk_aac_jll v2.0.4+0\u001b[39m\n",
      "  \u001b[90m[36db933b] \u001b[39m\u001b[92m+ libinput_jll v1.28.1+0\u001b[39m\n",
      "  \u001b[90m[b53b4c65] \u001b[39m\u001b[92m+ libpng_jll v1.6.55+0\u001b[39m\n",
      "  \u001b[90m[075b6546] \u001b[39m\u001b[92m+ libsixel_jll v1.10.5+0\u001b[39m\n",
      "  \u001b[90m[a9144af2] \u001b[39m\u001b[92m+ libsodium_jll v1.0.21+0\u001b[39m\n",
      "  \u001b[90m[f27f6e37] \u001b[39m\u001b[92m+ libvorbis_jll v1.3.8+0\u001b[39m\n",
      "  \u001b[90m[c5f90fcd] \u001b[39m\u001b[92m+ libwebp_jll v1.6.0+0\u001b[39m\n",
      "  \u001b[90m[337d8026] \u001b[39m\u001b[92m+ libzip_jll v1.11.3+0\u001b[39m\n",
      "  \u001b[90m[009596ad] \u001b[39m\u001b[92m+ mtdev_jll v1.1.7+0\u001b[39m\n",
      "  \u001b[90m[1317d2d5] \u001b[39m\u001b[92m+ oneTBB_jll v2022.0.0+1\u001b[39m\n",
      "\u001b[33m⌅\u001b[39m \u001b[90m[1270edf5] \u001b[39m\u001b[92m+ x264_jll v10164.0.1+0\u001b[39m\n",
      "  \u001b[90m[dfaa095f] \u001b[39m\u001b[92m+ x265_jll v4.1.0+0\u001b[39m\n",
      "  \u001b[90m[d8fb68d0] \u001b[39m\u001b[92m+ xkbcommon_jll v1.13.0+0\u001b[39m\n",
      "  \u001b[90m[0dad84c5] \u001b[39m\u001b[92m+ ArgTools v1.1.2\u001b[39m\n",
      "  \u001b[90m[56f22d72] \u001b[39m\u001b[92m+ Artifacts v1.11.0\u001b[39m\n",
      "  \u001b[90m[2a0f44e3] \u001b[39m\u001b[92m+ Base64 v1.11.0\u001b[39m\n",
      "  \u001b[90m[ade2ca70] \u001b[39m\u001b[92m+ Dates v1.11.0\u001b[39m\n",
      "  \u001b[90m[8ba89e20] \u001b[39m\u001b[92m+ Distributed v1.11.0\u001b[39m\n",
      "  \u001b[90m[f43a241f] \u001b[39m\u001b[92m+ Downloads v1.6.0\u001b[39m\n",
      "  \u001b[90m[7b1f6079] \u001b[39m\u001b[92m+ FileWatching v1.11.0\u001b[39m\n",
      "  \u001b[90m[9fa8497b] \u001b[39m\u001b[92m+ Future v1.11.0\u001b[39m\n",
      "  \u001b[90m[b77e0a4c] \u001b[39m\u001b[92m+ InteractiveUtils v1.11.0\u001b[39m\n",
      "  \u001b[90m[ac6e5ff7] \u001b[39m\u001b[92m+ JuliaSyntaxHighlighting v1.12.0\u001b[39m\n",
      "  \u001b[90m[4af54fe1] \u001b[39m\u001b[92m+ LazyArtifacts v1.11.0\u001b[39m\n",
      "  \u001b[90m[b27032c2] \u001b[39m\u001b[92m+ LibCURL v0.6.4\u001b[39m\n",
      "  \u001b[90m[76f85450] \u001b[39m\u001b[92m+ LibGit2 v1.11.0\u001b[39m\n",
      "  \u001b[90m[8f399da3] \u001b[39m\u001b[92m+ Libdl v1.11.0\u001b[39m\n",
      "  \u001b[90m[37e2e46d] \u001b[39m\u001b[93m~ LinearAlgebra ⇒ v1.12.0\u001b[39m\n",
      "  \u001b[90m[56ddb016] \u001b[39m\u001b[92m+ Logging v1.11.0\u001b[39m\n",
      "  \u001b[90m[d6f4376e] \u001b[39m\u001b[92m+ Markdown v1.11.0\u001b[39m\n",
      "  \u001b[90m[a63ad114] \u001b[39m\u001b[92m+ Mmap v1.11.0\u001b[39m\n",
      "  \u001b[90m[ca575930] \u001b[39m\u001b[92m+ NetworkOptions v1.3.0\u001b[39m\n",
      "  \u001b[90m[44cfe95a] \u001b[39m\u001b[92m+ Pkg v1.12.0\u001b[39m\n",
      "  \u001b[90m[de0858da] \u001b[39m\u001b[92m+ Printf v1.11.0\u001b[39m\n",
      "  \u001b[90m[9abbd945] \u001b[39m\u001b[92m+ Profile v1.11.0\u001b[39m\n",
      "  \u001b[90m[3fa0cd96] \u001b[39m\u001b[92m+ REPL v1.11.0\u001b[39m\n",
      "  \u001b[90m[9a3f8284] \u001b[39m\u001b[93m~ Random ⇒ v1.11.0\u001b[39m\n",
      "  \u001b[90m[ea8e919c] \u001b[39m\u001b[92m+ SHA v0.7.0\u001b[39m\n",
      "  \u001b[90m[9e88b42a] \u001b[39m\u001b[92m+ Serialization v1.11.0\u001b[39m\n",
      "  \u001b[90m[1a1011a3] \u001b[39m\u001b[92m+ SharedArrays v1.11.0\u001b[39m\n",
      "  \u001b[90m[6462fe0b] \u001b[39m\u001b[92m+ Sockets v1.11.0\u001b[39m\n",
      "  \u001b[90m[2f01184e] \u001b[39m\u001b[92m+ SparseArrays v1.12.0\u001b[39m\n",
      "  \u001b[90m[f489334b] \u001b[39m\u001b[92m+ StyledStrings v1.11.0\u001b[39m\n",
      "  \u001b[90m[4607b0f0] \u001b[39m\u001b[92m+ SuiteSparse\u001b[39m\n",
      "  \u001b[90m[fa267f1f] \u001b[39m\u001b[92m+ TOML v1.0.3\u001b[39m\n",
      "  \u001b[90m[a4e569a6] \u001b[39m\u001b[92m+ Tar v1.10.0\u001b[39m\n",
      "  \u001b[90m[8dfed614] \u001b[39m\u001b[93m~ Test ⇒ v1.11.0\u001b[39m\n",
      "  \u001b[90m[cf7118a7] \u001b[39m\u001b[92m+ UUIDs v1.11.0\u001b[39m\n",
      "  \u001b[90m[4ec0a83e] \u001b[39m\u001b[92m+ Unicode v1.11.0\u001b[39m\n",
      "  \u001b[90m[e66e0078] \u001b[39m\u001b[92m+ CompilerSupportLibraries_jll v1.3.0+1\u001b[39m\n",
      "  \u001b[90m[781609d7] \u001b[39m\u001b[92m+ GMP_jll v6.3.0+2\u001b[39m\n",
      "  \u001b[90m[deac9b47] \u001b[39m\u001b[92m+ LibCURL_jll v8.11.1+1\u001b[39m\n",
      "  \u001b[90m[e37daf67] \u001b[39m\u001b[92m+ LibGit2_jll v1.9.0+0\u001b[39m\n",
      "  \u001b[90m[29816b5a] \u001b[39m\u001b[92m+ LibSSH2_jll v1.11.3+1\u001b[39m\n",
      "  \u001b[90m[14a3606d] \u001b[39m\u001b[92m+ MozillaCACerts_jll v2025.5.20\u001b[39m\n",
      "  \u001b[90m[4536629a] \u001b[39m\u001b[92m+ OpenBLAS_jll v0.3.29+0\u001b[39m\n",
      "  \u001b[90m[05823500] \u001b[39m\u001b[92m+ OpenLibm_jll v0.8.7+0\u001b[39m\n",
      "  \u001b[90m[458c3c95] \u001b[39m\u001b[92m+ OpenSSL_jll v3.5.1+0\u001b[39m\n",
      "  \u001b[90m[efcefdf7] \u001b[39m\u001b[92m+ PCRE2_jll v10.44.0+1\u001b[39m\n",
      "  \u001b[90m[bea87d4a] \u001b[39m\u001b[92m+ SuiteSparse_jll v7.8.3+2\u001b[39m\n",
      "  \u001b[90m[83775a58] \u001b[39m\u001b[92m+ Zlib_jll v1.3.1+2\u001b[39m\n",
      "  \u001b[90m[8e850b90] \u001b[39m\u001b[92m+ libblastrampoline_jll v5.15.0+0\u001b[39m\n",
      "  \u001b[90m[8e850ede] \u001b[39m\u001b[92m+ nghttp2_jll v1.64.0+1\u001b[39m\n",
      "  \u001b[90m[3f19e933] \u001b[39m\u001b[92m+ p7zip_jll v17.5.0+2\u001b[39m\n",
      "\u001b[36m\u001b[1m        Info\u001b[22m\u001b[39m Packages marked with \u001b[32m⌃\u001b[39m and \u001b[33m⌅\u001b[39m have new versions available. Those with \u001b[32m⌃\u001b[39m may be upgradable, but those with \u001b[33m⌅\u001b[39m are restricted by compatibility constraints from upgrading. To see why use `status --outdated -m`\n",
      "\u001b[32m\u001b[1m    Building\u001b[22m\u001b[39m IJulia → `~/.julia/scratchspaces/44cfe95a-1eb2-52ea-b672-e2afdf69b78f/102656c4efc9737f892e1bca7e66ae374c650740/build.log`\n",
      "\u001b[32m\u001b[1mPrecompiling\u001b[22m\u001b[39m packages...\n",
      "    449.3 ms\u001b[32m  ✓ \u001b[39m\u001b[90mPtrArrays\u001b[39m\n",
      "    465.0 ms\u001b[32m  ✓ \u001b[39m\u001b[90mPreferences\u001b[39m\n",
      "    505.7 ms\u001b[32m  ✓ \u001b[39m\u001b[90mSolverCore\u001b[39m\n",
      "    509.1 ms\u001b[32m  ✓ \u001b[39m\u001b[90mAliasTables\u001b[39m\n",
      "    526.6 ms\u001b[32m  ✓ \u001b[39m\u001b[90mPrecompileTools\u001b[39m\n",
      "    532.0 ms\u001b[32m  ✓ \u001b[39m\u001b[90mJLLWrappers\u001b[39m\n",
      "   1408.1 ms\u001b[32m  ✓ \u001b[39m\u001b[90mLinearOperators\u001b[39m\n",
      "   1269.5 ms\u001b[32m  ✓ \u001b[39m\u001b[90mRecipesBase\u001b[39m\n",
      "   1484.5 ms\u001b[32m  ✓ \u001b[39m\u001b[90mStringManipulation\u001b[39m\n",
      "   2022.9 ms\u001b[32m  ✓ \u001b[39m\u001b[90mStatsBase\u001b[39m\n",
      "   2170.2 ms\u001b[32m  ✓ \u001b[39m\u001b[90mStatic\u001b[39m\n",
      "   5481.9 ms\u001b[32m  ✓ \u001b[39m\u001b[90mStaticArrays\u001b[39m\n",
      "    727.8 ms\u001b[32m  ✓ \u001b[39m\u001b[90mlibsodium_jll\u001b[39m\n",
      "    403.2 ms\u001b[32m  ✓ \u001b[39m\u001b[90mXorg_libICE_jll\u001b[39m\n",
      "    517.0 ms\u001b[32m  ✓ \u001b[39m\u001b[90mLibffi_jll\u001b[39m\n",
      "   3773.6 ms\u001b[32m  ✓ \u001b[39m\u001b[90mColorSchemes\u001b[39m\n",
      "    433.0 ms\u001b[32m  ✓ \u001b[39m\u001b[90mLibuuid_jll\u001b[39m\n",
      "    529.5 ms\u001b[32m  ✓ \u001b[39m\u001b[90mOpenSpecFun_jll\u001b[39m\n",
      "   7794.2 ms\u001b[32m  ✓ \u001b[39m\u001b[90mSIMD\u001b[39m\n",
      "    538.1 ms\u001b[32m  ✓ \u001b[39m\u001b[90mLLVMOpenMP_jll\u001b[39m\n",
      "    549.6 ms\u001b[32m  ✓ \u001b[39m\u001b[90mImath_jll\u001b[39m\n",
      "    571.7 ms\u001b[32m  ✓ \u001b[39m\u001b[90mfzf_jll\u001b[39m\n",
      "    603.9 ms\u001b[32m  ✓ \u001b[39m\u001b[90mJpegTurbo_jll\u001b[39m\n",
      "   1050.3 ms\u001b[32m  ✓ \u001b[39m\u001b[90mIntelOpenMP_jll\u001b[39m\n",
      "    420.2 ms\u001b[32m  ✓ \u001b[39m\u001b[90mmtdev_jll\u001b[39m\n",
      "    505.0 ms\u001b[32m  ✓ \u001b[39m\u001b[90mOgg_jll\u001b[39m\n",
      "    507.2 ms\u001b[32m  ✓ \u001b[39m\u001b[90mx265_jll\u001b[39m\n",
      "    517.3 ms\u001b[32m  ✓ \u001b[39m\u001b[90mx264_jll\u001b[39m\n",
      "    518.6 ms\u001b[32m  ✓ \u001b[39m\u001b[90mLibiconv_jll\u001b[39m\n",
      "    508.5 ms\u001b[32m  ✓ \u001b[39m\u001b[90mFriBidi_jll\u001b[39m\n",
      "   8574.5 ms\u001b[32m  ✓ \u001b[39m\u001b[90mParsers\u001b[39m\n",
      "    376.3 ms\u001b[32m  ✓ \u001b[39m\u001b[90mEpollShim_jll\u001b[39m\n",
      "    482.8 ms\u001b[32m  ✓ \u001b[39m\u001b[90mGraphite2_jll\u001b[39m\n",
      "    400.6 ms\u001b[32m  ✓ \u001b[39m\u001b[90mXorg_libXau_jll\u001b[39m\n",
      "    479.5 ms\u001b[32m  ✓ \u001b[39m\u001b[90mlibpng_jll\u001b[39m\n",
      "    460.8 ms\u001b[32m  ✓ \u001b[39m\u001b[90mGiflib_jll\u001b[39m\n",
      "    474.6 ms\u001b[32m  ✓ \u001b[39m\u001b[90mLAME_jll\u001b[39m\n",
      "    437.8 ms\u001b[32m  ✓ \u001b[39m\u001b[90mXorg_libXdmcp_jll\u001b[39m\n",
      "    497.4 ms\u001b[32m  ✓ \u001b[39m\u001b[90mArpack_jll\u001b[39m\n",
      "    535.2 ms\u001b[32m  ✓ \u001b[39m\u001b[90mlibaom_jll\u001b[39m\n",
      "    534.1 ms\u001b[32m  ✓ \u001b[39m\u001b[90mMbedTLS_jll\u001b[39m\n",
      "    511.0 ms\u001b[32m  ✓ \u001b[39m\u001b[90mZstd_jll\u001b[39m\n",
      "    485.6 ms\u001b[32m  ✓ \u001b[39m\u001b[90mExpat_jll\u001b[39m\n",
      "    559.1 ms\u001b[32m  ✓ \u001b[39m\u001b[90mLZO_jll\u001b[39m\n",
      "    483.9 ms\u001b[32m  ✓ \u001b[39m\u001b[90mOpus_jll\u001b[39m\n",
      "    395.0 ms\u001b[32m  ✓ \u001b[39m\u001b[90mXorg_xtrans_jll\u001b[39m\n",
      "    420.3 ms\u001b[32m  ✓ \u001b[39m\u001b[90meudev_jll\u001b[39m\n",
      "    454.0 ms\u001b[32m  ✓ \u001b[39m\u001b[90mLibmount_jll\u001b[39m\n",
      "    481.1 ms\u001b[32m  ✓ \u001b[39m\u001b[90mBzip2_jll\u001b[39m\n",
      "    550.1 ms\u001b[32m  ✓ \u001b[39m\u001b[90mRmath_jll\u001b[39m\n",
      "    518.5 ms\u001b[32m  ✓ \u001b[39m\u001b[90mlibfdk_aac_jll\u001b[39m\n",
      "    490.0 ms\u001b[32m  ✓ \u001b[39m\u001b[90mLERC_jll\u001b[39m\n",
      "    557.4 ms\u001b[32m  ✓ \u001b[39m\u001b[90mXZ_jll\u001b[39m\n",
      "    413.0 ms\u001b[32m  ✓ \u001b[39m\u001b[90mlibevdev_jll\u001b[39m\n",
      "    513.1 ms\u001b[32m  ✓ \u001b[39m\u001b[90mFFTW_jll\u001b[39m\n",
      "    509.6 ms\u001b[32m  ✓ \u001b[39m\u001b[90mGLPK_jll\u001b[39m\n",
      "    985.7 ms\u001b[32m  ✓ \u001b[39m\u001b[90moneTBB_jll\u001b[39m\n",
      "    879.5 ms\u001b[32m  ✓ \u001b[39m\u001b[90mLinearOperators → LinearOperatorsLDLFactorizationsExt\u001b[39m\n",
      "    597.1 ms\u001b[32m  ✓ \u001b[39m\u001b[90mLinearOperators → LinearOperatorsChainRulesCoreExt\u001b[39m\n",
      "    612.5 ms\u001b[32m  ✓ \u001b[39m\u001b[90mIntervalSets → IntervalSetsRecipesBaseExt\u001b[39m\n",
      "  12577.5 ms\u001b[32m  ✓ \u001b[39m\u001b[90mImageCore\u001b[39m\n",
      "   1252.7 ms\u001b[32m  ✓ \u001b[39m\u001b[90mNLPModels\u001b[39m\n",
      "    545.2 ms\u001b[32m  ✓ \u001b[39m\u001b[90mBitTwiddlingConvenienceFunctions\u001b[39m\n",
      "    902.9 ms\u001b[32m  ✓ \u001b[39m\u001b[90mPDMats → StatsBaseExt\u001b[39m\n",
      "    393.9 ms\u001b[32m  ✓ \u001b[39m\u001b[90mCPUSummary\u001b[39m\n",
      "    691.5 ms\u001b[32m  ✓ \u001b[39m\u001b[90mStaticArrays → StaticArraysStatisticsExt\u001b[39m\n",
      "    647.6 ms\u001b[32m  ✓ \u001b[39m\u001b[90mStaticArrays → StaticArraysChainRulesCoreExt\u001b[39m\n",
      "    726.1 ms\u001b[32m  ✓ \u001b[39m\u001b[90mCoordinateTransformations\u001b[39m\n",
      "   1082.6 ms\u001b[32m  ✓ \u001b[39m\u001b[90mArnoldiMethod\u001b[39m\n",
      "    512.3 ms\u001b[32m  ✓ \u001b[39m\u001b[90mConstructionBase → ConstructionBaseStaticArraysExt\u001b[39m\n",
      "    534.2 ms\u001b[32m  ✓ \u001b[39m\u001b[90mRegionTrees\u001b[39m\n",
      "    493.1 ms\u001b[32m  ✓ \u001b[39m\u001b[90mFillArrays → FillArraysStaticArraysExt\u001b[39m\n",
      "    460.0 ms\u001b[32m  ✓ \u001b[39m\u001b[90mAdapt → AdaptStaticArraysExt\u001b[39m\n",
      "   1369.3 ms\u001b[32m  ✓ \u001b[39m\u001b[90mRotations\u001b[39m\n",
      "    405.7 ms\u001b[32m  ✓ \u001b[39m\u001b[90mXorg_libSM_jll\u001b[39m\n",
      "    747.8 ms\u001b[32m  ✓ \u001b[39m\u001b[90mZeroMQ_jll\u001b[39m\n",
      "   2221.4 ms\u001b[32m  ✓ \u001b[39m\u001b[90mSpecialFunctions\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "include(joinpath(@__DIR__, \"Include.jl\")); # include the Include.jl file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726cd62b",
   "metadata": {},
   "source": [
    "In addition to standard Julia libraries, we'll also use [the `VLDataScienceMachineLearningPackage.jl` package](https://github.com/varnerlab/VLDataScienceMachineLearningPackage.jl). Check out [the documentation](https://varnerlab.github.io/VLDataScienceMachineLearningPackage.jl/dev/) for more information on the functions, types, and data used in this material."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e1261c",
   "metadata": {},
   "source": [
    "### Data\n",
    "Let's load [a dataset from the `LIBSVM` data archive](https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/) that describes the detection of non-coding RNA sequences that was initially published by:\n",
    "* [Andrew V Uzilov, Joshua M Keegan, and David H Mathews. Detection of non-coding RNAs on the basis of predicted secondary structure formation free energy change. BMC Bioinformatics, 7(173), 2006.](https://pubmed.ncbi.nlm.nih.gov/16566836/)\n",
    "\n",
    "\n",
    "Non-coding RNAs (ncRNAs) have many roles in cells. However, detecting novel ncRNAs in biochemical screens is challenging. Accurate computational methods for detecting ncRNAs in sequenced genomes are important to understanding the roles ncRNAs play in cells. \n",
    "\n",
    "> __What's in the dataset?__\n",
    "> \n",
    "> In this dataset, there are `59535` training instances in the `training` data; each instance has `8` continuous features and a binary label $y\\in\\left\\{-1,1\\right\\}$, where a label of `1` indicates that the RNA sequence is non-coding and a label of `-1` indicates that the RNA sequence is coding. \n",
    "> \n",
    "> The features are continuous values for each RNA sequence pair consisting of Dynalign-predicted total folding free energy (`ΔG_total`), the shorter-sequence length, and the A/U/C nucleotide frequencies for each sequence.\n",
    "> \n",
    "> The `test` dataset has `271617` instances (with the same `8` continuous features and a binary label).\n",
    "\n",
    "We begin by loading the `training` and `test` datasets. The [`LIBSVM` library authors](https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/) have developed these subsets. Let's start by setting some constants and then loading the data. Please look at the comment next to the constant for a definition of what it is, units, permissible values, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0241898c",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_features = 8; # there are eight continuous features\n",
    "number_of_tests_to_run = 1000; # how many test examples to run through the KNN algorithm?\n",
    "number_of_reference_samples = 10001; # how many training examples to use as reference samples for the KNN algorithm?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f750f3",
   "metadata": {},
   "source": [
    "In the code block below we preprocess the `training` dataset. We have [z-score centered](https://en.wikipedia.org/wiki/Standard_score) the training data and combined it into an array where each row is a training instance, while the first `1:number_of_features` columns hold the features. The last column has the label. \n",
    "\n",
    "We store the training data in the `training::Array{NamedTuple,1}` array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033a7a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "training = let\n",
    "\n",
    "    # load the training data -\n",
    "    data = parser(joinpath(_PATH_TO_DATA, \"cod-rna-training.data\"));\n",
    "    number_of_rows = size(data,1);\n",
    "    data_perm = randperm(number_of_rows);\n",
    "    training_data = Array{NamedTuple,1}(undef, number_of_rows);\n",
    "    X = data[data_perm,:];\n",
    "    \n",
    "    # z-score center the data -\n",
    "    μ = mean(X[:,1:number_of_features],dims=1);\n",
    "    σ = std(X[:,1:number_of_features],dims=1);\n",
    "    X̂ = zeros(number_of_rows,number_of_features+1);\n",
    "    for i ∈ 1:number_of_rows\n",
    "        for j ∈ 1:number_of_features\n",
    "            X̂[i,j] = (X[i,j] - μ[j])/(σ[j]);\n",
    "        end\n",
    "        X̂[i,end] = X[i,end]; # get the label\n",
    "    end\n",
    "\n",
    "    # package the data into an array of named tuples -\n",
    "    for i ∈ 1:number_of_rows\n",
    "        features = X̂[i,1:number_of_features];\n",
    "        label = X̂[i,end];\n",
    "        training_data[i] = (x = features, y = (label |> Int ));\n",
    "    end\n",
    "\n",
    "    training_data; # return scaled - balanced data\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57fd5436",
   "metadata": {},
   "source": [
    "Next, we preprocess the `test` dataset.  We [z-score center](https://en.wikipedia.org/wiki/Standard_score) the test data and combined it into an array where each row is a test instance, while the first `1:number_of_features` columns hold the features. The last column has the label.\n",
    "\n",
    "We store the test data in the `test::Array{NamedTuple,1}` array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b067bc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = let\n",
    "\n",
    "    # load the training data -\n",
    "    data = parser(joinpath(_PATH_TO_DATA, \"cod-rna-testing.data\"));\n",
    "    number_of_rows = size(data,1);\n",
    "    data_perm = randperm(number_of_rows);\n",
    "    test_data = Array{NamedTuple,1}(undef, number_of_rows);\n",
    "    X = data[data_perm,:];\n",
    "    \n",
    "    # z-score center the data -\n",
    "    μ = mean(X[:,1:number_of_features],dims=1);\n",
    "    σ = std(X[:,1:number_of_features],dims=1);\n",
    "    X̂ = zeros(number_of_rows,number_of_features+1);\n",
    "    for i ∈ 1:number_of_rows\n",
    "        for j ∈ 1:number_of_features\n",
    "            X̂[i,j] = (X[i,j] - μ[j])/(σ[j]);\n",
    "        end\n",
    "        X̂[i,end] = X[i,end]; # get the label\n",
    "    end\n",
    "\n",
    "    # package the data into an array of named tuples -\n",
    "    for i ∈ 1:number_of_rows\n",
    "        features = X̂[i,1:number_of_features];\n",
    "        label = X̂[i,end];\n",
    "        test_data[i] = (x=features, y = (label |> Int ));\n",
    "    end\n",
    "\n",
    "    test_data; # return scaled - balanced data\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f38bb0",
   "metadata": {},
   "source": [
    "> __Are the labels in the training dataset balanced?__\n",
    ">\n",
    "> Since we are using a KNN classifier, it is important to check label balance in the reference dataset. If labels are imbalanced, neighbor voting can bias predictions toward the majority class and reduce minority-class performance.\n",
    "\n",
    "Let's compute the positive and negative label fractions in the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224314eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "let \n",
    "\n",
    "    # initialize -\n",
    "    D = training; # specify what data set we are working with\n",
    "    number_of_training_examples = length(D); # how many examples are in the training dataset?\n",
    "\n",
    "    # Fancy! Let's use a list comprehension to count the number of positive and negative labels in the training dataset. The `sum()` function will sum up the number of times the condition is true for each example in the training dataset.\n",
    "    count_positive_labels = sum(D[i].y == 1 for i ∈ 1:number_of_training_examples); # how many positive labels are in the training dataset?\n",
    "    count_negative_labels = sum(D[i].y == -1 for i ∈ 1:number_of_training_examples); # how many negative labels are in the training dataset?\n",
    "    \n",
    "    # print the results (fraction of positive and negative labels in the training dataset)\n",
    "    println(\"Fraction of positive labels in the training dataset: \", count_positive_labels / number_of_training_examples);\n",
    "    println(\"Fraction of negative labels in the training dataset: \", count_negative_labels / number_of_training_examples);\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574ae6de",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffbfa5a2",
   "metadata": {},
   "source": [
    "## Task 2: Let's look at our KNN Classifier\n",
    "In this task, we will build and evaluate the KNN classifier that we will be using to make predictions on the test dataset. We'll build [a `MyWeightedKernelizedKNNClassificationModel` model](https://varnerlab.github.io/VLDataScienceMachineLearningPackage.jl/dev/binaryclassification/#VLDataScienceMachineLearningPackage.MyWeightedKernelizedKNNClassificationModel) using the `training` dataset as the reference data.\n",
    "\n",
    "Let's build a kernel function $k:\\mathbb{R}^{m}\\times\\mathbb{R}^{m}\\to\\mathbb{R}$ to measure similarity. For now, let's make up our own kernel function, and save this function in the `k(x,y)::Function` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa8a5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "k(x,y,γ) = exp(-γ * norm(x-y,2)^2) # RBF kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c56aaf7",
   "metadata": {},
   "source": [
    "#### Check: Are we using a valid Kernel function?\n",
    "Let's check to see if the distance (similarity) metric we built is a valid kernel function.\n",
    "\n",
    "> __Condition:__\n",
    ">\n",
    "> A function $k:\\mathbb{R}^{m}\\times\\mathbb{R}^{m}\\to\\mathbb{R}$ is a _valid kernel function_ if and only if the kernel matrix $\\mathbf{K}\\in\\mathbb{R}^{n\\times{n}}$ is positive (semi)definite for all possible choices of the data vectors $\\mathbf{v}_i$, where $K_{ij} = k(\\mathbf{v}_i, \\mathbf{v}_j)$. If $\\mathbf{K}$ is positive (semi)definite, then for any real-valued vector $\\mathbf{x} \\in \\mathbb{R}^n$, the kernel matrix $\\mathbf{K}$ must satisfy $\\mathbf{x}^{\\top}\\mathbf{K}\\mathbf{x} \\geq 0$. \n",
    "\n",
    "Let's compute the kernel matrix `KM::Array{Float64,2}` for a data matrix `X::Array{Float64,2}` using the distance/kernel function `k(x,y)::Function` we built above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4dfa6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "KM = let\n",
    "\n",
    "    D = training; # specify what data set we are working with\n",
    "    number_of_training_examples = 100; # how many examples are in the training dataset (we will use only small number examples to compute the kernel matrix for computational efficiency)\n",
    "    number_of_features = D[1].x |> length; # number of features in the dataset\n",
    "    γ = 0.5; # kernel parameter\n",
    "\n",
    "    # fill up the feature matrix -\n",
    "    X = zeros(number_of_training_examples, number_of_features); # initialize a matrix to hold the features\n",
    "    for i ∈ 1:number_of_training_examples\n",
    "        X[i,:] = D[i].x; # fill the matrix with the features from the training dataset\n",
    "    end\n",
    "\n",
    "    # fill up the kernel matrix -\n",
    "    K = zeros(number_of_training_examples,number_of_training_examples);\n",
    "    for i ∈ 1:number_of_training_examples\n",
    "        vᵢ = X[i,:];\n",
    "        for j ∈ 1:number_of_training_examples\n",
    "            vⱼ = X[j,:];\n",
    "            K[i,j] = k(vᵢ,vⱼ,γ) # compute kernel value\n",
    "        end\n",
    "    end\n",
    "    K\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115937a2",
   "metadata": {},
   "source": [
    "Next, let's check to see if the kernel matrix `K::Array{Float64,2}` is positive (semi)definite by checking if all of its eigenvalues are non-negative.\n",
    "\n",
    "> __Check:__\n",
    ">\n",
    "> For this kernel to be valid, the kernel matrix $\\mathbf{K}$ needs to be positive (semi)definite, i.e., all eigenvalues $\\lambda_i \\geq 0$. We compute the eigenvalues using [`eigvals`](https://docs.julialang.org/en/v1/stdlib/LinearAlgebra/#LinearAlgebra.eigvals) and verify they are all non-negative using [the `@assert` macro](https://docs.julialang.org/en/v1/base/base/#Base.@assert) in combination with [the `all` function](https://docs.julialang.org/en/v1/base/collections/#Base.all-Tuple%7BAny%7D).\n",
    "\n",
    "Do we blow up? If not, the matrix is PSD for this dataset, which supports using this kernel in this lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae360c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "let\n",
    "    λ = eigvals(KM);\n",
    "    @assert all(λ .≥ -1e-10) \"Kernel matrix is not PSD: min eigenvalue = $(minimum(λ))\"\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1840d7",
   "metadata": {},
   "source": [
    "Ok, so now let's build the KNN classifier model. There are a few design choices to make, such as the number of neighbors to consider (`K`), the kernel function, and any kernel parameters. \n",
    "\n",
    "> __How do we choose the `K` parameter?__\n",
    ">\n",
    "> The choice of `K` controls the bias-variance tradeoff: __bias__ means a systematic error from an oversimplified neighborhood vote, and __variance__ means sensitivity to which training points happen to be in the dataset. \n",
    "> \n",
    "> A small `K` uses local voting (low bias, high variance), while large `K` uses global voting (high bias, low variance). We use $K = mC + 1$, where $m \\geq 0$ is adjustable and $C$ is the number of classes, to explore this tradeoff systematically. \n",
    "\n",
    "Can we see this tradeoff in action by varying `K`? Let's test that on the dataset. Next let's consider our second design choice: the kernel width parameter $\\gamma$ in the RBF kernel.\n",
    "\n",
    "> __Gating parameter $\\gamma$:__\n",
    ">\n",
    "> The parameter $\\gamma>0$ controls how quickly similarity decays with squared distance in $k(\\mathbf{x},\\mathbf{y})=\\exp\\left(-\\gamma\\lVert\\mathbf{x}-\\mathbf{y}\\rVert_2^2\\right)$. Larger $\\gamma$ makes the similarity measure more sensitive, so even small-to-moderate $\\lVert\\mathbf{x}-\\mathbf{y}\\rVert_2^2$ values can drive similarity toward zero and emphasize very local neighbors. Smaller $\\gamma$ makes the kernel less sensitive, so even larger squared-distance differences can still produce moderate similarity and allow more distant neighbors to influence the vote.\n",
    "\n",
    "Let's see how varying $\\gamma$ and the number of neighbors `K` affects the performance of our KNN classifier on the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92cee9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = let\n",
    "    \n",
    "    # initialize -\n",
    "    D = training; # specify what data set we are working with\n",
    "    number_of_training_examples = number_of_reference_samples; # how many examples are in the training dataset?\n",
    "    number_of_features = D[1].x |> length; # number of features in the dataset\n",
    "    γ = 0.50; # kernel parameter\n",
    "    m = 10; # neighborhood size multiple\n",
    "    C = 2; # number of classes\n",
    "\n",
    "    # fill up the feature matrix -\n",
    "    X = zeros(number_of_training_examples, number_of_features); # initialize a matrix to hold the features\n",
    "    for i ∈ 1:number_of_training_examples\n",
    "        X[i,:] = D[i].x; # fill the matrix with the features from the training dataset\n",
    "    end\n",
    "\n",
    "    # fill up the label vector -\n",
    "    y = zeros(number_of_training_examples); # initialize a vector to hold the labels\n",
    "    for i ∈ 1:number_of_training_examples\n",
    "        y[i] = D[i].y; # fill the vector with the labels from the training dataset\n",
    "    end\n",
    "\n",
    "    # build a model -\n",
    "    model = build(MyWeightedKernelizedKNNClassificationModel, (\n",
    "        K = (m*C+1), # we look at this many points\n",
    "        features = X,\n",
    "        labels = y,\n",
    "        k = (x,y) -> k(x,y,γ), # RBF kernel similarity metric\n",
    "    ));\n",
    "\n",
    "    model; # return the model\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b38ed5",
   "metadata": {},
   "source": [
    "### Inference\n",
    "Now that we have defined a kernel function, and built the model, let's use it to classify our data. We use the KNN classifier from [the `VLDataScienceMachineLearningPackage.jl` package](https://github.com/varnerlab/VLDataScienceMachineLearningPackage.jl). \n",
    "\n",
    "> __What is going on in this code block?__\n",
    ">\n",
    "> In the code block below, we:\n",
    "> * Construct [a `MyWeightedKernelizedKNNClassificationModel` model](https://varnerlab.github.io/VLDataScienceMachineLearningPackage.jl/dev/binaryclassification/#VLDataScienceMachineLearningPackage.MyWeightedKernelizedKNNClassificationModel) using [a `build(...)` method](https://varnerlab.github.io/VLDataScienceMachineLearningPackage.jl/dev/factory/). The `model` instance holds the data for the problem, i.e., how many neighbors to look at `K`, and the kernel function $k$.\n",
    "> * Next, we pass this `model` instance to [the `classify(...)` method](https://varnerlab.github.io/VLDataScienceMachineLearningPackage.jl/dev/binaryclassification/#VLDataScienceMachineLearningPackage.classify) which takes a test feature $\\mathbf{z}$ and the classifier `model` instance and returns the predicted label value $\\hat{y}$ for the test feature vector $\\mathbf{z}$.\n",
    "\n",
    "We return the predicted labels in `ŷ_KNN` and the actual labels in `y_KNN`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a60a189",
   "metadata": {},
   "outputs": [],
   "source": [
    "ŷ_KNN,y_KNN = let\n",
    "\n",
    "    # Data -\n",
    "    D = test; # what dataset are we working with?\n",
    "    number_of_test_examples = number_of_tests_to_run; # how many samples are we going to test?\n",
    "    number_of_features = D[1].x |> length; # number of features in the dataset\n",
    "\n",
    "     # fill up the feature matrix -\n",
    "    X = zeros(number_of_test_examples, number_of_features); # initialize a matrix to hold the features\n",
    "    for i ∈ 1:number_of_test_examples\n",
    "        X[i,:] = D[i].x; # fill the matrix with the features from the test dataset\n",
    "    end\n",
    "\n",
    "    # fill up the label vector (actual labels) -\n",
    "    y = zeros(number_of_test_examples); # initialize a vector to hold the labels\n",
    "    for i ∈ 1:number_of_test_examples\n",
    "        y[i] = D[i].y; # fill the vector with the labels from the test dataset\n",
    "    end\n",
    "\n",
    "    # process each vector in the test set, compare that to training (reference), and compute the predicted label -\n",
    "    ŷ = zeros(number_of_test_examples);  # initialize some storage for the predicted label\n",
    "    for i ∈ 1:number_of_test_examples\n",
    "        z = X[i,:]; # get feature vector for test\n",
    "        ŷ[i] = classify(z,model) # classify the test vector using the training data\n",
    "    end\n",
    " \n",
    "    # return -\n",
    "    ŷ,y\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3502e44",
   "metadata": {},
   "source": [
    "### Performance\n",
    "We can evaluate the binary classifier's performance using various metrics. The central idea is to compare the predicted labels $\\hat{y}_{i}$ to the actual labels $y_{i}$ in the `test` dataset and measure wins (when the label is the same) and losses (label is different). This is easily represented in [the confusion matrix](https://en.wikipedia.org/wiki/Confusion_matrix).\n",
    "\n",
    "> __Error analysis using the confusion matrix__\n",
    ">\n",
    "> Total mistakes (or mistake percentage) is only part of the story. We should understand whether we are biased toward false positives or false negatives for RNA labels. \n",
    ">\n",
    "> The confusion matrix for a binary classifier is typically structured as:\n",
    ">\n",
    ">|                     | **Predicted Positive** | **Predicted Negative** |\n",
    ">|---------------------|------------------------|------------------------|\n",
    ">| **Actual Positive** | True Positive (TP)     | False Negative (FN)    |\n",
    ">| **Actual Negative** | False Positive (FP)    | True Negative (TN)     |\n",
    ">\n",
    "> From the confusion matrix, we derive five key metrics:\n",
    ">\n",
    "> * __Accuracy__ is the fraction of correct predictions overall: $\\texttt{accuracy} = \\frac{TP + TN}{TP + TN + FP + FN}$. It tells us the overall success rate but can be misleading if classes are imbalanced; a classifier that predicts \"negative\" for everything might achieve 95% accuracy on an imbalanced dataset.\n",
    "> * __Precision__ answers: \"When we predict positive, how often are we right?\" $\\texttt{precision} = \\frac{TP}{TP + FP}$. In this RNA context, high precision means fewer false positives; if we predict non-coding, that prediction is usually correct. Low precision means many coding sequences are predicted as non-coding.\n",
    "> * __Recall__ (also called sensitivity) answers: \"Of all the true positives, how many did we catch?\" $\\texttt{recall} = \\frac{TP}{TP + FN}$. High recall means we are catching most non-coding sequences. Low recall means many non-coding sequences are predicted as coding.\n",
    "> * __Balanced Accuracy__ averages recall (sensitivity) and specificity: $\\texttt{balanced\\_accuracy} = \\frac{1}{2}\\left(\\frac{TP}{TP + FN} + \\frac{TN}{TN + FP}\\right)$. A high balanced accuracy means the model performs well on both classes, while a low balanced accuracy means the model is weak on at least one class.\n",
    "> * __F1 Score__ is the harmonic mean of precision and recall: $\\texttt{F1} = \\frac{2\\cdot\\texttt{precision}\\cdot\\texttt{recall}}{\\texttt{precision} + \\texttt{recall}}$. A high F1 means we are balancing missed positives and false positives well, while a low F1 means one or both of those error types are large.\n",
    "\n",
    "We compute the __confusion matrix__ to get these counts. We use the [confusion(...) method](https://varnerlab.github.io/VLDataScienceMachineLearningPackage.jl/dev/binaryclassification/#VLDataScienceMachineLearningPackage.confusion), which takes actual labels and estimated labels, returning the confusion matrix. We save the confusion matrix in the `CM_KNN::Array{Int64,2}` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf9c2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "CM_KNN = confusion(y_KNN,ŷ_KNN)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3cea59",
   "metadata": {},
   "source": [
    "Let's compute the __accuracy__, __precision__, __recall__, __balanced_accuracy__, and __f1__ for our KNN classifier using the confusion matrix. We save these metrics in the `accuracy_KNN::Float64`, `precision_KNN::Float64`, `recall_KNN::Float64`, `balanced_accuracy_KNN::Float64`, and `f1_KNN::Float64` variables, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da638bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_KNN, precision_KNN, recall_KNN, balanced_accuracy_KNN, f1_KNN = let\n",
    "\n",
    "    # compute the confusion matrix -\n",
    "    CM = CM_KNN; # confusion matrix for KNN classifier\n",
    "\n",
    "    # compute accuracy, precision, recall, balanced accuracy, and F1 -\n",
    "    TP = CM[1,1]; # true positives\n",
    "    TN = CM[2,2]; # true negatives\n",
    "    FP = CM[2,1]; # false positives\n",
    "    FN = CM[1,2]; # false negatives\n",
    "\n",
    "    accuracy = (TP + TN) / sum(CM); # overall accuracy\n",
    "    precision = (TP + FP) == 0 ? 0.0 : TP / (TP + FP); # precision\n",
    "    recall = (TP + FN) == 0 ? 0.0 : TP / (TP + FN); # recall\n",
    "    specificity = (TN + FP) == 0 ? 0.0 : TN / (TN + FP); # specificity\n",
    "    balanced_accuracy = 0.5 * (recall + specificity); # balanced accuracy\n",
    "    f1 = (precision + recall) == 0 ? 0.0 : 2 * precision * recall / (precision + recall); # F1 score\n",
    "\n",
    "    # print so the user can see -\n",
    "    println(\"KNN Accuracy: $(round(accuracy*100,digits=2))%\")\n",
    "    println(\"KNN Precision: $(round(precision*100,digits=2))%\")\n",
    "    println(\"KNN Recall: $(round(recall*100,digits=2))%\")\n",
    "    println(\"KNN Balanced Accuracy: $(round(balanced_accuracy*100,digits=2))%\")\n",
    "    println(\"KNN f1: $(round(f1*100,digits=2))%\")\n",
    "\n",
    "    (accuracy, precision, recall, balanced_accuracy, f1); # return the metrics\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8e6d63",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "356c3d6b",
   "metadata": {},
   "source": [
    "## Task 3: Let's do a hyperparameter sweep\n",
    "In this task, we perform a grid search to see how the number of neighbors `K` and kernel gating parameter $\\gamma$ affect classification performance on the test dataset.\n",
    "\n",
    "> __What is going on in this code block?__\n",
    ">\n",
    "> We sweep over several $\\left(K,\\gamma\\right)$ combinations. For each pair, we build a `MyWeightedKernelizedKNNClassificationModel`, classify every test point, compute a confusion matrix, then calculate accuracy, precision, recall, F1, and balanced accuracy. Finally, we sort all results (by F1) so the best precision-recall tradeoff settings appear first.\n",
    "\n",
    "Let's execute the sweep and inspect the top-performing settings. We store the results in the `knn_sweep_results::DataFrame` variable, which contains the `K`, `gamma`, `TP`, `TN`, `FP`, `FN`, `accuracy`, `precision`, `recall`, `f1`, and `balanced_accuracy` values for each combination. We sort this DataFrame by F1 in descending order to see the strongest precision-recall settings at the top."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9644994",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_sweep_results = let\n",
    "\n",
    "    # load data -\n",
    "    Dtr = training;\n",
    "    Dte = test;\n",
    "    ntr = number_of_reference_samples; # how many training examples do we have?\n",
    "    number_of_test_examples = number_of_tests_to_run; # how many samples are we going to test?\n",
    "\n",
    "    # feature/label arrays for training -\n",
    "    Xtr = zeros(ntr, number_of_features);\n",
    "    ytr = zeros(ntr);\n",
    "    for i in 1:ntr\n",
    "        Xtr[i, :] = Dtr[i].x;\n",
    "        ytr[i] = Dtr[i].y;\n",
    "    end\n",
    "\n",
    "    # feature/label arrays for test -\n",
    "    Xte = zeros(number_of_test_examples, number_of_features);\n",
    "    yte = zeros(number_of_test_examples);\n",
    "    for i in 1:number_of_test_examples\n",
    "        Xte[i, :] = Dte[i].x;\n",
    "        yte[i] = Dte[i].y;\n",
    "    end\n",
    "\n",
    "    # hyperparameter grids -\n",
    "    K_grid = [3, 5, 9, 15, 25, 41, 65, 101, 151, 201, 301];\n",
    "    γ_grid = [0.01, 0.05, 0.10, 0.25, 0.50];\n",
    "\n",
    "    # initialize a DataFrame to hold the results of the sweep -\n",
    "    results = DataFrame(\n",
    "        K = Int[],\n",
    "        gamma = Float64[],\n",
    "        TP = Int[],\n",
    "        TN = Int[],\n",
    "        FP = Int[],\n",
    "        FN = Int[],\n",
    "        accuracy = Float64[],\n",
    "        precision = Float64[],\n",
    "        recall = Float64[],\n",
    "        f1 = Float64[],\n",
    "        balanced_accuracy = Float64[]\n",
    "    );\n",
    "\n",
    "    # sweep all (K, gamma) combinations -\n",
    "    for γ ∈ γ_grid\n",
    "        for K_neighbors ∈ K_grid\n",
    "            \n",
    "            # Create a local model for this combination of hyperparameters -\n",
    "            model_local = build(MyWeightedKernelizedKNNClassificationModel, (\n",
    "                K = K_neighbors, # we are looking at this many neighbors\n",
    "                features = Xtr,\n",
    "                labels = ytr,\n",
    "                k = (x, y) -> k(x, y, γ), # RBF kernel with the current gamma\n",
    "            ));\n",
    "\n",
    "            # classify test set -\n",
    "            ŷ = zeros(number_of_test_examples);\n",
    "            for i ∈ 1:number_of_test_examples\n",
    "                ŷ[i] = classify(Xte[i, :], model_local);\n",
    "            end\n",
    "\n",
    "            # confusion-matrix metrics -\n",
    "            CM = confusion(yte, ŷ);\n",
    "            TP = CM[1, 1]; # true positives\n",
    "            TN = CM[2, 2]; # true negatives\n",
    "            FP = CM[2, 1]; # false positives\n",
    "            FN = CM[1, 2]; # false negatives\n",
    "\n",
    "            accuracy = (TP + TN) / sum(CM);\n",
    "            precision = (TP + FP) == 0 ? 0.0 : TP / (TP + FP);\n",
    "            recall = (TP + FN) == 0 ? 0.0 : TP / (TP + FN);\n",
    "\n",
    "            specificity = (TN + FP) == 0 ? 0.0 : TN / (TN + FP)\n",
    "            balanced_accuracy = 0.5 * (recall + specificity)\n",
    "            f1_score = (precision + recall) == 0 ? 0.0 : 2 * precision * recall / (precision + recall)\n",
    "\n",
    "\n",
    "            # package results into the DataFrame -\n",
    "            push!(results, (\n",
    "                K = K_neighbors, # how many neighbors were used?\n",
    "                gamma = γ, # what was the kernel parameter?\n",
    "                TP = TP, # true positives\n",
    "                TN = TN, # true negatives\n",
    "                FP = FP, # false positives\n",
    "                FN = FN, # false negatives\n",
    "                accuracy = accuracy, # overall accuracy\n",
    "                precision = precision, # precision\n",
    "                recall = recall, # recall\n",
    "                f1 = f1_score, # F1 score\n",
    "                balanced_accuracy = balanced_accuracy, # balanced accuracy\n",
    "            ));\n",
    "        end\n",
    "    end\n",
    "\n",
    "    # sort the results -\n",
    "    df = sort(results, :f1, rev = true); # sort results by F1 (descending order);\n",
    "    df[1:10, :] # return the top 10 results\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf487be9",
   "metadata": {},
   "source": [
    "Next, let's build a table of the results from our hyperparameter search using [the `pretty_table(...)` function exported by the `PrettyTables.jl` package](https://github.com/ronisbr/PrettyTables.jl)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1644efc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Display the top rows of `knn_sweep_results` using pretty_table.\n",
    "\n",
    "#=\n",
    "pretty_table(knn_sweep_results; \n",
    "    backend = :text,\n",
    "    fit_table_in_display_horizontally = false,\n",
    "    table_format = TextTableFormat(borders = text_table_borders__compact)\n",
    ");\n",
    "=#\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf99f29",
   "metadata": {},
   "source": [
    "## Discussion\n",
    "We now have set up our KNN classifier for the RNA sequence classification task. Let's explore some of the results and discuss what we see."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb361a5",
   "metadata": {},
   "source": [
    "**DQ1: Why is feature scaling essential for KNN on this RNA dataset?** KNN predictions are driven by distances between feature vectors. If one feature (for example, sequence length or total folding energy) spans a much larger numeric range than the nucleotide-frequency features, it can dominate distance calculations and bias neighbor voting.\n",
    "\n",
    "> __Strategy__: Use the preprocessing cells to explain what z-score scaling is doing here and why it matters for Euclidean-distance KNN with an RBF kernel. In 2-3 sentences, describe what could go wrong if we skipped scaling and which features would likely dominate (you can modify the scaling cell to explore your answer).\n",
    "\n",
    "Write your response in the next code cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3613ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer DQ1 here after evaluating why scaling matters for KNN distances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c50fb5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "did_I_answer_DQ1 = false; # TODO: update to true if answered DQ1 {true | false}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6ca139",
   "metadata": {},
   "source": [
    "**DQ2: What do accuracy, precision, recall, balanced accuracy, and F1 mean for this RNA classification problem?** This dataset is class-imbalanced, so high accuracy can still occur even when the model misses many true positives. Precision and recall tell us different things about false positives versus false negatives, which can change how we judge model quality.\n",
    "\n",
    "> __Strategy__: Using `CM_KNN`, `accuracy_KNN`, `precision_KNN`, `recall_KNN`, `balanced_accuracy_KNN`, and `f1_KNN`, interpret each metric in the context of predicting RNA class labels. In 2-3 sentences, state whether this model is better at ruling out negatives or finding positives, and which metric you would prioritize for this task.\n",
    "\n",
    "Write your response in the next code cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cabddf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer DQ2 here after interpreting CM_KNN and the three metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6efb66d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "did_I_answer_DQ2 = false; # TODO: update to true if answered DQ2 {true | false}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e29054",
   "metadata": {},
   "source": [
    "**DQ3: What does the hyperparameter sweep tell us about KNN behavior on this dataset?** The `knn_sweep_results` table shows how changing `K` and `gamma` affects TP, TN, FP, FN, and the derived metrics. Similar accuracies can still correspond to very different precision/recall tradeoffs, which reveals what the model is optimizing in practice.\n",
    "\n",
    "> __Strategy__: Inspect the top-performing and lower-performing rows in `knn_sweep_results`. In 2-3 sentences, describe the trend you see as `K` and `gamma` change, and explain what that suggests about local-vs-global voting and the model's ability to recover positive examples.\n",
    "\n",
    "Write your response in the next code cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188b410d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer DQ3 here after analyzing trends in `knn_sweep_results`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e0d72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "did_I_answer_DQ3 = false; # TODO: update to true if answered DQ3 {true | false}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495ee274",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b48d9ace",
   "metadata": {},
   "source": [
    "## Summary\n",
    "This problem set implemented an end-to-end kernelized KNN workflow for classifying RNA sequences as coding or non-coding.\n",
    "\n",
    "> __Key Takeaways:__\n",
    ">\n",
    "> * **Feature scaling controls distance behavior:** Z-score scaling puts all features on comparable numeric ranges before neighbor search. Without scaling, large-range features can dominate distances and distort KNN votes.\n",
    "> * **Confusion-matrix metrics reveal different error modes:** Accuracy summarizes total correctness across both classes. Precision and recall show whether the model is producing too many false non-coding calls or missing true non-coding sequences.\n",
    "> * **Hyperparameter sweeps expose model tradeoffs:** Changing `K` and `gamma` changes how local the voting behavior is and how fast similarity decays. Similar accuracy values can hide large recall differences, so parameter selection should match the task objective.\n",
    "\n",
    "The next step is to choose `K` and `gamma` based on the error type you want to minimize for RNA screening.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17fddd90",
   "metadata": {},
   "source": [
    "## Tests\n",
    "In the code block below, we check some values in your notebook and give you feedback on which items are correct or different. `Unhide` the code block below (if you are curious) about how we implemented the tests and what we are testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b23c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "let\n",
    "    @testset verbose = true \"CHEME 5820 problem set 3 test suite\" begin\n",
    "\n",
    "        @testset \"Setup, Data, and Prerequisites\" begin\n",
    "            @test number_of_features == 8\n",
    "            @test number_of_tests_to_run > 0\n",
    "            @test number_of_reference_samples > 0\n",
    "            @test isnothing(training) == false\n",
    "            @test isnothing(test) == false\n",
    "            @test length(training) > number_of_reference_samples\n",
    "            @test length(test) > number_of_tests_to_run\n",
    "\n",
    "            ncheck_train = min(1000, length(training))\n",
    "            ncheck_test = min(1000, length(test))\n",
    "            @test all(d -> length(d.x) == number_of_features, training[1:ncheck_train])\n",
    "            @test all(d -> length(d.x) == number_of_features, test[1:ncheck_test])\n",
    "            @test all(d -> d.y in (-1, 1), training[1:ncheck_train])\n",
    "            @test all(d -> d.y in (-1, 1), test[1:ncheck_test])\n",
    "\n",
    "            count_positive_labels_training = sum(training[i].y == 1 for i in eachindex(training))\n",
    "            count_negative_labels_training = sum(training[i].y == -1 for i in eachindex(training))\n",
    "            count_positive_labels_test = sum(test[i].y == 1 for i in eachindex(test))\n",
    "            count_negative_labels_test = sum(test[i].y == -1 for i in eachindex(test))\n",
    "            @test count_positive_labels_training > 0\n",
    "            @test count_negative_labels_training > 0\n",
    "            @test count_positive_labels_test > 0\n",
    "            @test count_negative_labels_test > 0\n",
    "        end\n",
    "\n",
    "        @testset \"Task 2: Kernel Function, Model, and Inference\" begin\n",
    "            @test isnothing(k) == false\n",
    "            @test k(training[1].x, training[2].x, 0.5) isa Real\n",
    "\n",
    "            @test isnothing(KM) == false\n",
    "            km_n1, km_n2 = size(KM)\n",
    "            @test km_n1 == km_n2\n",
    "            @test km_n1 >= 2\n",
    "            @test all(isfinite, KM)\n",
    "            @test isapprox(KM, transpose(KM), atol=1e-8)\n",
    "            @test all(isapprox.(diag(KM), 1.0, atol=1e-8))\n",
    "            λ = eigvals(Symmetric(KM))\n",
    "            @test minimum(λ) >= -1e-8\n",
    "\n",
    "            @test isnothing(model) == false\n",
    "            @test length(ŷ_KNN) == number_of_tests_to_run\n",
    "            @test length(y_KNN) == number_of_tests_to_run\n",
    "            @test all(v -> v in (-1.0, 1.0), ŷ_KNN)\n",
    "            @test all(v -> v in (-1.0, 1.0), y_KNN)\n",
    "        end\n",
    "\n",
    "        @testset \"Task 2: Confusion Matrix and Metrics\" begin\n",
    "            @test isnothing(CM_KNN) == false\n",
    "            @test size(CM_KNN) == (2, 2)\n",
    "            @test all(CM_KNN .>= 0)\n",
    "            @test sum(CM_KNN) == number_of_tests_to_run\n",
    "\n",
    "            TP = CM_KNN[1,1]\n",
    "            TN = CM_KNN[2,2]\n",
    "            FP = CM_KNN[2,1]\n",
    "            FN = CM_KNN[1,2]\n",
    "\n",
    "            accuracy_expected = (TP + TN) / sum(CM_KNN)\n",
    "            precision_expected = (TP + FP) == 0 ? 0.0 : TP / (TP + FP)\n",
    "            recall_expected = (TP + FN) == 0 ? 0.0 : TP / (TP + FN)\n",
    "            specificity_expected = (TN + FP) == 0 ? 0.0 : TN / (TN + FP)\n",
    "            balanced_accuracy_expected = 0.5 * (recall_expected + specificity_expected)\n",
    "            f1_expected = (precision_expected + recall_expected) == 0 ? 0.0 : 2 * precision_expected * recall_expected / (precision_expected + recall_expected)\n",
    "\n",
    "            @test 0.0 <= accuracy_KNN <= 1.0\n",
    "            @test 0.0 <= precision_KNN <= 1.0\n",
    "            @test 0.0 <= recall_KNN <= 1.0\n",
    "            @test 0.0 <= balanced_accuracy_KNN <= 1.0\n",
    "            @test 0.0 <= f1_KNN <= 1.0\n",
    "            @test isapprox(accuracy_KNN, accuracy_expected, atol=1e-12)\n",
    "            @test isapprox(precision_KNN, precision_expected, atol=1e-12)\n",
    "            @test isapprox(recall_KNN, recall_expected, atol=1e-12)\n",
    "            @test isapprox(balanced_accuracy_KNN, balanced_accuracy_expected, atol=1e-12)\n",
    "            @test isapprox(f1_KNN, f1_expected, atol=1e-12)\n",
    "        end\n",
    "\n",
    "        @testset \"Task 3: Hyperparameter Sweep\" begin\n",
    "            @test isnothing(knn_sweep_results) == false\n",
    "            @test nrow(knn_sweep_results) > 0\n",
    "            @test names(knn_sweep_results) == [\"K\", \"gamma\", \"TP\", \"TN\", \"FP\", \"FN\", \"accuracy\", \"precision\", \"recall\", \"f1\", \"balanced_accuracy\"]\n",
    "            @test issorted(knn_sweep_results.f1, rev=true)\n",
    "            @test all(knn_sweep_results.K .> 0)\n",
    "            @test all(isodd.(knn_sweep_results.K))\n",
    "            @test all(knn_sweep_results.gamma .> 0.0)\n",
    "            @test all((knn_sweep_results.TP .+ knn_sweep_results.TN .+ knn_sweep_results.FP .+ knn_sweep_results.FN) .== number_of_tests_to_run)\n",
    "            @test all((0.0 .<= knn_sweep_results.accuracy) .& (knn_sweep_results.accuracy .<= 1.0))\n",
    "            @test all((0.0 .<= knn_sweep_results.precision) .& (knn_sweep_results.precision .<= 1.0))\n",
    "            @test all((0.0 .<= knn_sweep_results.recall) .& (knn_sweep_results.recall .<= 1.0))\n",
    "            @test all((0.0 .<= knn_sweep_results.f1) .& (knn_sweep_results.f1 .<= 1.0))\n",
    "            @test all((0.0 .<= knn_sweep_results.balanced_accuracy) .& (knn_sweep_results.balanced_accuracy .<= 1.0))\n",
    "\n",
    "            for row in eachrow(knn_sweep_results)\n",
    "                TP = row.TP\n",
    "                TN = row.TN\n",
    "                FP = row.FP\n",
    "                FN = row.FN\n",
    "\n",
    "                accuracy_expected = (TP + TN) / (TP + TN + FP + FN)\n",
    "                precision_expected = (TP + FP) == 0 ? 0.0 : TP / (TP + FP)\n",
    "                recall_expected = (TP + FN) == 0 ? 0.0 : TP / (TP + FN)\n",
    "                specificity_expected = (TN + FP) == 0 ? 0.0 : TN / (TN + FP)\n",
    "                balanced_accuracy_expected = 0.5 * (recall_expected + specificity_expected)\n",
    "                f1_expected = (precision_expected + recall_expected) == 0 ? 0.0 : 2 * precision_expected * recall_expected / (precision_expected + recall_expected)\n",
    "\n",
    "                @test isapprox(row.accuracy, accuracy_expected, atol=1e-12)\n",
    "                @test isapprox(row.precision, precision_expected, atol=1e-12)\n",
    "                @test isapprox(row.recall, recall_expected, atol=1e-12)\n",
    "                @test isapprox(row.balanced_accuracy, balanced_accuracy_expected, atol=1e-12)\n",
    "                @test isapprox(row.f1, f1_expected, atol=1e-12)\n",
    "            end\n",
    "        end\n",
    "\n",
    "        @testset \"Discussion Questions\" begin\n",
    "            @test did_I_answer_DQ1 == true\n",
    "            @test did_I_answer_DQ2 == true\n",
    "            @test did_I_answer_DQ3 == true\n",
    "        end\n",
    "    end\n",
    "end;"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.12.1",
   "language": "julia",
   "name": "julia-1.12"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
